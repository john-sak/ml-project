{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "lyroKUvuXgTM",
        "E8oZ4uXmXoha",
        "O7lXSUs0e_x_",
        "KEEGYAcqfMNF",
        "OgXCBD-pfQMA"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Σακαρέλλος Ιωάννης - sdi1800167"
      ],
      "metadata": {
        "id": "Kd-KzSkR9G7U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkhqIgWoNxF0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49b8df61-41c3-4e89-cf00-dc9ff652f3f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import librosa.display\n",
        "\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n",
        "from torch.optim import SGD\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/gdrive/MyDrive/Machine Learning/HW3/Data/data.zip' -d '/content/gdrive/MyDrive/Machine Learning/HW3/Data/'\n",
        "\n",
        "\n",
        "data_url = r'/content/gdrive/MyDrive/Machine Learning/HW3/Data/music_genre_data_di'\n",
        "\n",
        "mapping = {'blues' : 0,\n",
        "           'classical' : 1,\n",
        "           'hiphop' : 2,\n",
        "           'rock_metal_hardrock' : 3}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8VGgkbEA5VT",
        "outputId": "e5f780d2-6aef-411e-da40-de9fd2c35d25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/gdrive/MyDrive/Machine Learning/HW3/Data/data.zip\n",
            "replace /content/gdrive/MyDrive/Machine Learning/HW3/Data/music_genre_data_di/test/melgrams/X.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ερώτημα 1: Feedforward Neural Network"
      ],
      "metadata": {
        "id": "pMIhWGObBpLs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Βήμα 1: Φόρτωση Δεδομένων (MFCCs)"
      ],
      "metadata": {
        "id": "vt0ExTNYBzek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mfcc_trainX = np.load(data_url + '/train/mfccs/X.npy')\n",
        "mfcc_trainY = np.load(data_url + '/train/mfccs/labels.npy')\n",
        "\n",
        "mfcc_testX = np.load(data_url + '/test/mfccs/X.npy')\n",
        "mfcc_testY = np.load(data_url + '/test/mfccs/labels.npy')\n",
        "\n",
        "mfcc_valX = np.load(data_url + '/val/mfccs/X.npy')\n",
        "mfcc_valY = np.load(data_url + '/val/mfccs/labels.npy')"
      ],
      "metadata": {
        "id": "qez-7Y_TzlyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mfcc_trainY = np.array([mapping[label] for label in mfcc_trainY])\n",
        "\n",
        "mfcc_testY = np.array([mapping[label] for label in mfcc_testY])\n",
        "\n",
        "mfcc_valY = np.array([mapping[label] for label in mfcc_valY])"
      ],
      "metadata": {
        "id": "WjTvKGCOzudZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mfcc_trainX[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhzWlx1_6os3",
        "outputId": "202a1f4b-0de0-4255-cc64-982d54f8a269"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.62640284e+01,  3.50238316e+00,  1.08797911e+00,  3.99411198e-01,\n",
              "        5.33732920e-01,  3.13589575e-01, -2.48267521e-02,  2.64692240e-01,\n",
              "        1.83268396e-02,  6.04936474e-02, -2.37525896e-01, -2.91073564e-03,\n",
              "        3.44489057e-02,  1.51350842e+00,  6.21633735e-01,  3.05950256e-01,\n",
              "        2.60451193e-01,  1.79726246e-01,  2.07318222e-01,  2.77934742e-01,\n",
              "        2.13824074e-01,  1.78887478e-01,  1.28970384e-01,  2.00535542e-01,\n",
              "        1.69736069e-01,  1.83230535e-01])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class trainDataSetMFCC(Dataset):\n",
        "  def __init__(self):\n",
        "    self.x = torch.Tensor(mfcc_trainX.tolist())\n",
        "    self.y = torch.LongTensor(mfcc_trainY.tolist())\n",
        "\n",
        "    self.n_samples = len(self.x)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.x[index], self.y[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_samples\n",
        "\n",
        "\n",
        "class testDataSetMFCC(Dataset):\n",
        "  def __init__(self):\n",
        "    self.x = torch.Tensor(mfcc_testX.tolist())\n",
        "    self.y = torch.LongTensor(mfcc_testY.tolist())\n",
        "\n",
        "    self.n_samples = len(self.x)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.x[index], self.y[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_samples\n",
        "\n",
        "\n",
        "class valDataSetMFCC(Dataset):\n",
        "  def __init__(self):\n",
        "    self.x = torch.Tensor(mfcc_valX.tolist())\n",
        "    self.y = torch.LongTensor(mfcc_valY.tolist())\n",
        "\n",
        "    self.n_samples = len(self.x)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.x[index], self.y[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_samples"
      ],
      "metadata": {
        "id": "yIY5lyw7Toco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainLoaderMFCC = DataLoader(dataset=trainDataSetMFCC(), batch_size=16, shuffle=True)\n",
        "\n",
        "testLoaderMFCC = DataLoader(dataset=testDataSetMFCC(), batch_size=16, shuffle=False)\n",
        "\n",
        "valLoaderMFCC = DataLoader(dataset=valDataSetMFCC(), batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "id": "obKiJzEg9qHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Βήμα 2: Ορισμός Νευρωνικού Δικτύου"
      ],
      "metadata": {
        "id": "ptS9_35H-HdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NN(nn.Module):\n",
        "  def __init__(self, input_size=26, num_classes=4):\n",
        "    super(NN, self).__init__()\n",
        "\n",
        "    self.fc1 = nn.Linear(input_size, 128)\n",
        "    self.fc2 = nn.Linear(128, 32)\n",
        "    self.fc3 = nn.Linear(32, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "o9WxFUcO-QzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Βήμα 3: Ορισμός Διαδικασίας Εκπαίδευσης"
      ],
      "metadata": {
        "id": "JRt2ebB04w4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(epochs, optimizer, dataloader, cost_func, model, device='cpu'):\n",
        "  device = torch.device(device)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    print('Epoch No ', epoch, '\\n================', sep='')\n",
        "\n",
        "    for batch, (data, targets) in enumerate(dataloader):\n",
        "      data = data.to(device=device)\n",
        "      targets = targets.to(device=device)\n",
        "\n",
        "      scores = model(data)\n",
        "      loss = cost_func(scores, targets)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      print('Batch No ', batch, ',\\tloss is ', loss, sep='')\n",
        "\n",
        "    print('')\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "hpqt0CIE41Jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Βήμα 4: Ορισμός Διαδικασίας Αξιολόγησης"
      ],
      "metadata": {
        "id": "xa04qjCE_JMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(dataloader, cost_func, model, device='cpu'):\n",
        "  device = torch.device(device)\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "\n",
        "    scores_all = []\n",
        "    targets_all = []\n",
        "\n",
        "    for data, targets in dataloader:\n",
        "      data = data.to(device=device)\n",
        "      targets = targets.to(device=device)\n",
        "\n",
        "      scores = model(data)\n",
        "\n",
        "      scores_all.append(scores)\n",
        "      targets_all.append(targets)\n",
        "\n",
        "    scores_all = torch.cat(scores_all, 0).cpu()\n",
        "    targets_all = torch.cat(targets_all, 0).cpu()\n",
        "\n",
        "    _, pred = scores_all.max(1)\n",
        "\n",
        "    loss = cost_func(scores_all, targets_all)\n",
        "    f1 = f1_score(targets_all, pred, average='macro')\n",
        "    acc = accuracy_score(targets_all, pred)\n",
        "    mat = confusion_matrix(targets_all, pred)\n",
        "\n",
        "    print('Loss:\\t\\t\\t\\t', loss)\n",
        "    print('F1 Macro-Averaged Score:\\t', f1)\n",
        "    print('Accuracy:\\t\\t\\t', acc)\n",
        "    print('Confusion Matrix:\\t', mat, '\\n')\n",
        "\n",
        "  model.train()"
      ],
      "metadata": {
        "id": "RvVd0nMl_Pht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Βήμα 5: Εκπαίδευση Δικτύου"
      ],
      "metadata": {
        "id": "73mM3EXsE-xj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NN(input_size=26, num_classes=4).to(torch.device('cpu'))\n",
        "\n",
        "train_model(epochs=30, optimizer=SGD(model.parameters(), lr=0.002), dataloader=trainLoaderMFCC, cost_func=nn.CrossEntropyLoss(), model=model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOhhXbzAFDE2",
        "outputId": "f79c045b-ce13-42bb-a086-951c225e6289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Batch No 73,\tloss is tensor(1.3579, grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.3345, grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.3450, grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.3641, grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.3580, grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.3679, grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(1.3153, grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.3714, grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.3366, grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.3447, grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.3377, grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.3699, grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.3648, grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.3566, grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.3213, grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.3655, grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.2936, grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.3636, grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.3543, grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.3953, grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.4102, grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.3623, grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.3678, grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.3464, grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.3633, grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.3370, grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.3376, grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.3655, grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.3298, grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.3598, grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.4065, grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.3494, grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.3317, grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.3817, grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.3390, grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.3666, grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.4034, grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.3494, grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.3619, grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.3394, grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.3632, grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.3543, grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.3376, grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.3547, grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.3502, grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.3536, grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.3410, grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.3598, grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.3815, grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.3479, grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.3566, grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.3441, grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.3522, grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.3572, grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.3925, grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.4011, grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.3671, grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.3324, grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.3410, grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.3912, grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.3659, grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.3477, grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.3454, grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.3473, grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.3640, grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.3594, grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(1.3413, grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.3426, grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.3613, grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.3467, grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.3894, grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.3605, grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.3658, grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.3569, grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.3790, grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(1.3406, grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.3797, grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.3449, grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.3452, grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.3798, grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.3367, grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.3566, grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.3471, grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.3420, grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.3349, grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.3299, grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.3470, grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.3405, grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.3701, grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.3014, grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.3244, grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.3873, grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.3437, grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.4163, grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.3723, grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.3310, grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.3303, grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.3835, grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.3197, grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.3703, grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.3349, grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.3829, grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.3336, grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.3540, grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.3580, grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.3635, grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.3651, grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.3603, grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.3355, grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.3558, grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.3770, grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.3851, grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.3597, grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.3670, grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.3527, grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.3766, grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.3504, grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.3876, grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.3628, grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.3429, grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.3483, grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.3511, grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.3572, grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.3332, grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.3615, grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.3627, grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.3656, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 6\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.3399, grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.3323, grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.3597, grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.3603, grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.3705, grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.3536, grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.3630, grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.3669, grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.3573, grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.3559, grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.3596, grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.3561, grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.3532, grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.3407, grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.3361, grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.3735, grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.3536, grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.3431, grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.3655, grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.3413, grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.3462, grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.3711, grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.3514, grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.3445, grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.3440, grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.3083, grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.3659, grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(1.3259, grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.3539, grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(1.3227, grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.3689, grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.3475, grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.3524, grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(1.3384, grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.3452, grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.3850, grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.2828, grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.3664, grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.3470, grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.3640, grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.3475, grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.3746, grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.3484, grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(1.3470, grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.3737, grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.3646, grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.3658, grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.3256, grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.3160, grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.3621, grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.3655, grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.3709, grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.3352, grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.3418, grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.3487, grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.3628, grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.3580, grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.3708, grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.3412, grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.3691, grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.3666, grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.3552, grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.3353, grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.3184, grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.3757, grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.3254, grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.3579, grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.3645, grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.3470, grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.3111, grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.3790, grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.3308, grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.3288, grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.3813, grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.3818, grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.3590, grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.3404, grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.3473, grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.2986, grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(1.3950, grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.3277, grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.3646, grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.3462, grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.3578, grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.4009, grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.3657, grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.3592, grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.3528, grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.3252, grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.3226, grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.3364, grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.3299, grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.3103, grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.3368, grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.3109, grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.3539, grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.3409, grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.3245, grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.3759, grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.3366, grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.3600, grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.3327, grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.3301, grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.3717, grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.3422, grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.3969, grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.3612, grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.3649, grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.3383, grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.3378, grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.3511, grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.3303, grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.3498, grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.3197, grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.3881, grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.2885, grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.2911, grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.3475, grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.3376, grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.3984, grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.3915, grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.3509, grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.3628, grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.3381, grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.3331, grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.3638, grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.3602, grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.3530, grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.3546, grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.3558, grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.3572, grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.3591, grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.3203, grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.3330, grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.3515, grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.3241, grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.3388, grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.3540, grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.3709, grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(1.3314, grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.3339, grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.3578, grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.3161, grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.3553, grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.3061, grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.3720, grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.3466, grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.3132, grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(1.3765, grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.3494, grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.3393, grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.3740, grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.3673, grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.3516, grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.3416, grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.3191, grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.3435, grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.3547, grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.3630, grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.3335, grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.3579, grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.3529, grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.3399, grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.3242, grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.3776, grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.3538, grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.3609, grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.3488, grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.3410, grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.3780, grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.3526, grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.3382, grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.3130, grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.3532, grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.3528, grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.3652, grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.3301, grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.3444, grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.3535, grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.3420, grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.3996, grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.3494, grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.3849, grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.3457, grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.3662, grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.3657, grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.3547, grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.3425, grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.3383, grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.3688, grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.3793, grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.3346, grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.3347, grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.3491, grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.3673, grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.3199, grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.3652, grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.3460, grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.3055, grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.3971, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 7\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.3805, grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.3522, grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.3451, grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.3429, grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.3213, grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.3139, grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.3341, grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.3372, grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.4024, grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.3408, grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.3210, grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.3298, grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.3427, grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.3256, grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.3675, grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.3529, grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.3095, grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.3619, grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.3663, grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.3401, grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.3145, grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.3619, grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.3661, grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.3487, grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.3471, grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.3513, grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(1.3374, grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.3638, grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(1.3344, grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.3054, grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.3308, grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.3487, grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(1.3767, grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.3265, grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.3498, grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.3374, grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.3536, grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.3445, grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.3759, grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.3301, grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.3266, grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.3314, grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(1.3603, grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.3312, grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.3788, grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.3510, grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.3106, grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.3676, grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.3707, grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.3163, grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.3555, grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.3351, grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.3257, grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.3353, grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.3351, grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.3506, grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.3333, grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.3672, grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.3810, grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.3608, grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.3271, grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.3454, grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.3369, grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.3523, grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.3414, grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.3268, grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.3221, grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.3681, grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.3324, grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.3022, grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.3025, grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.3896, grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.3394, grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.3268, grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.2532, grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.3998, grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.3947, grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.3649, grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(1.3627, grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.3190, grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.2936, grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.3404, grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.3612, grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.3728, grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.3263, grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.3707, grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.2947, grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.3343, grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.2949, grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.3630, grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.3333, grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.3335, grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.3894, grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.3195, grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.3239, grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.3137, grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.4048, grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.3232, grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.3708, grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.3368, grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.3356, grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.3312, grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.3435, grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.3404, grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.3561, grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.3372, grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.3761, grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.3800, grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.3346, grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.3374, grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.3611, grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.3397, grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.3170, grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.3786, grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.3504, grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.3311, grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.3357, grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.3273, grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.3325, grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.3630, grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.3486, grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.3287, grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.3508, grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.3448, grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.3518, grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.3591, grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.3329, grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.3266, grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.3545, grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.3461, grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.3400, grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.3696, grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.3438, grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.3371, grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.3513, grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.3467, grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.3263, grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.3306, grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(1.3366, grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.3396, grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.3311, grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.3097, grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.3613, grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.2982, grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.3279, grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.3364, grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.3286, grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(1.3524, grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.3819, grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.2728, grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.3582, grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.3461, grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.3855, grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.3272, grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.3185, grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.3452, grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.3067, grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.3594, grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.2948, grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.3139, grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.2998, grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.3477, grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.3243, grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.2799, grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.3667, grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.2969, grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.3577, grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.3677, grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.3738, grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.3611, grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.2999, grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.3004, grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.2698, grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.3543, grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.3731, grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.2685, grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.3522, grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.3079, grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.3607, grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.3697, grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.3681, grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.3456, grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.3159, grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.3078, grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.3595, grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.3618, grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.3319, grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.3774, grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.3681, grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.3321, grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.3075, grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.3483, grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.3874, grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.3418, grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.3434, grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.3448, grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.3337, grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.3277, grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.3517, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 8\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.3431, grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.3321, grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.3075, grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.3346, grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.3374, grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.3584, grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.3328, grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.3069, grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.3211, grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.3512, grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.3409, grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.3297, grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.2991, grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.3352, grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.3378, grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.3210, grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.3510, grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.3376, grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.3284, grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.3340, grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.3278, grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.3263, grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.3070, grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.2993, grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.2973, grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.4049, grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.3316, grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(1.3127, grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.3744, grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(1.3108, grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.3357, grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.3336, grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.2712, grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(1.3036, grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.3561, grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.2667, grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.3330, grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.3604, grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.2824, grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.2994, grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.3473, grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.3514, grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.3266, grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(1.2835, grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.3265, grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.2989, grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.3558, grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.3255, grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.3674, grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.3502, grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.3399, grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.3428, grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.3216, grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.3250, grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.3369, grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.3973, grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.3348, grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.2258, grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.3840, grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.3201, grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.3713, grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.2933, grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.4047, grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.3716, grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.3226, grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.3759, grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.3181, grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.3527, grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.3578, grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.3453, grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.3685, grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.3141, grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.3094, grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.3604, grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.2987, grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.3549, grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.3264, grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.3176, grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.3605, grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(1.3492, grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.3187, grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.2858, grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.2660, grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.3246, grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.3470, grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.3505, grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.3339, grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.3465, grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.3111, grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.3417, grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.3193, grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.3045, grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.3169, grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.3688, grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.3053, grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.3038, grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.3291, grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.2941, grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.3595, grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.3588, grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.3394, grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.3314, grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.3311, grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.3383, grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.3775, grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.3247, grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.3048, grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.3478, grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.3444, grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.3172, grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.3575, grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.3525, grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.3384, grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.3543, grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.2973, grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.3043, grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.3643, grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.3202, grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.3082, grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.3443, grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.3291, grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.3677, grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.3417, grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.3162, grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.3358, grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.3273, grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.3567, grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.3438, grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.3439, grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.3154, grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.3421, grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.3164, grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.2945, grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.3075, grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.3051, grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.3227, grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.3355, grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.2940, grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.3040, grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(1.2781, grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.4089, grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.3981, grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.3534, grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.3313, grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.3455, grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.3341, grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.3308, grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.3030, grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(1.3216, grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.3329, grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.3368, grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.3163, grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.3256, grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.3126, grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.3748, grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.3345, grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.3549, grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.3216, grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.3751, grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.3528, grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.3457, grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.3244, grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.3574, grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.3147, grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.2940, grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.3441, grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.3457, grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.3400, grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.3343, grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.3393, grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.3478, grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.3623, grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.3437, grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.3392, grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.2812, grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.2759, grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.3810, grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.3350, grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.3377, grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.3387, grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.3437, grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.3012, grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.3420, grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.3267, grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.3168, grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.3476, grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.3134, grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.3398, grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.3349, grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.3080, grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.3295, grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.3153, grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.3483, grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.3454, grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.3572, grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.2984, grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.3101, grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.3412, grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.3353, grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.3024, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 9\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.3467, grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.3420, grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.3253, grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.3350, grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.2893, grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.3379, grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.3637, grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.3110, grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.3321, grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.3293, grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.3281, grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.2956, grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.3231, grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.3020, grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.3203, grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.3376, grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.3224, grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.3555, grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.3420, grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.3316, grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.3289, grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.3086, grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.3059, grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.3554, grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.3745, grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.3636, grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.3161, grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(1.3367, grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.3053, grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(1.3590, grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.3000, grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.3002, grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.3049, grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(1.3404, grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.3484, grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.3197, grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.3263, grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.3128, grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.3096, grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.3132, grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.3376, grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.3057, grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.3620, grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(1.3120, grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.3515, grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.3052, grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.2592, grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.3340, grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.3541, grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.3447, grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.3509, grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.2964, grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.3230, grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.3103, grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.3589, grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.3576, grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.3245, grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.3234, grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.3074, grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.3355, grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.3383, grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.2995, grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.2666, grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.3405, grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.3958, grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.3026, grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.3395, grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.3296, grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.3261, grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.3188, grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.3271, grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.3160, grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.2973, grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.2940, grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.2863, grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.2963, grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.3496, grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.2923, grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.3509, grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(1.3279, grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.3153, grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.3195, grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.3602, grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.3301, grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.3355, grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.3634, grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.3246, grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.3187, grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.3402, grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.3349, grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.3401, grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.3061, grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.3215, grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.3199, grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.2754, grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.2761, grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.2829, grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.2883, grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.2317, grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.3299, grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.2858, grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.3333, grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.3639, grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.3623, grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.3695, grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.2982, grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.3633, grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.2951, grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.3192, grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.3173, grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.3240, grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.2826, grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.2948, grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.3512, grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.3803, grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.3903, grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.3274, grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.2792, grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.3374, grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.3115, grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.3105, grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.3203, grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.3401, grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.3273, grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.2935, grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.2743, grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.3634, grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.3086, grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.3341, grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.3271, grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.3174, grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.3534, grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.3048, grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.2642, grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.3057, grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.3275, grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.3296, grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.2997, grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.3000, grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(1.2914, grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.3079, grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.3008, grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.3464, grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.3071, grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.3049, grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.3351, grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.3572, grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.3080, grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(1.3042, grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.3032, grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.3026, grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.2413, grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.2887, grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.3066, grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.2851, grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.3282, grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.3428, grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.3191, grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.2638, grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.3438, grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.3630, grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.2505, grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.3814, grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.2393, grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.3226, grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.2890, grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.3122, grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.3294, grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.3764, grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.3509, grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.3348, grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.3255, grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.3183, grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.3294, grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.3808, grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.3124, grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.3000, grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.3274, grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.3756, grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.2959, grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.2977, grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.3830, grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.3521, grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.3131, grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.3409, grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.3123, grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.3507, grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.3585, grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.2772, grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.2449, grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.3389, grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.2725, grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.3210, grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.3680, grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.3464, grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.3183, grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.3652, grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.3165, grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.2953, grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.2509, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 10\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.3055, grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.3081, grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.2967, grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.2403, grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.2479, grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.3809, grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.3385, grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.2855, grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.3370, grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.2745, grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.3467, grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.2960, grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.3024, grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.3354, grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.3142, grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.3504, grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.3134, grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.3141, grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.3189, grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.3156, grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.2664, grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.2879, grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.3171, grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.3177, grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.3423, grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.3024, grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.3235, grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(1.3295, grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.3199, grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(1.3000, grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.3335, grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.3258, grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.3577, grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(1.3508, grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.2967, grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.2978, grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.2953, grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.2552, grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.3138, grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.2992, grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.3197, grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.3341, grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.2972, grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(1.2695, grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.2690, grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.3148, grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.2780, grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.3938, grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.3134, grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.3332, grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.2522, grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.3620, grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.3274, grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.2718, grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.3080, grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.3241, grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.2816, grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.3185, grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.3356, grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.3438, grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.3456, grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.3123, grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.3042, grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.2701, grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.2781, grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.2512, grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.3329, grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.3637, grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.1994, grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.2300, grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.3615, grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.3460, grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.3054, grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.3374, grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.3273, grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.2745, grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.3257, grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.3157, grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.2774, grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(1.4325, grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.3586, grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.3412, grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.2964, grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.2557, grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.3001, grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.2903, grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.2678, grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.3413, grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.3173, grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.3098, grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.2715, grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.3627, grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.2159, grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.3094, grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.2827, grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.3060, grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.2980, grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.2666, grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.4086, grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.3366, grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.3385, grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.3517, grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.3397, grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.3180, grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.2326, grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.3694, grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.2953, grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.2975, grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.3012, grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.3423, grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.3154, grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.3142, grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.2454, grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.1973, grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.3308, grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.3702, grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.2960, grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.2401, grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.3469, grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.3259, grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.3000, grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.2876, grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.3523, grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.3659, grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.3210, grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.2094, grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.3599, grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.3176, grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.2731, grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.2966, grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.3499, grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.3094, grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.3492, grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.2559, grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.2876, grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.3065, grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.2629, grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.3205, grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.2808, grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(1.2558, grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.3638, grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.3114, grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.2829, grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.2713, grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.3575, grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.3009, grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.2867, grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.2962, grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(1.3486, grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.2690, grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.3512, grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.2382, grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.3173, grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.2659, grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.3159, grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.2501, grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.2273, grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.2574, grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.3656, grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.2342, grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.3370, grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.2555, grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.2483, grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.3991, grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.3223, grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.2390, grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.2980, grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.3945, grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.3424, grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.2978, grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.3786, grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.3094, grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.3009, grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.3207, grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.3577, grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.3004, grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.3280, grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.3524, grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.3407, grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.2903, grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.3097, grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.3217, grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.3032, grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.2854, grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.3551, grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.2921, grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.3086, grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.3662, grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.3507, grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.3222, grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.3179, grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.2983, grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.3419, grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.2777, grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.2800, grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.3567, grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.2505, grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.3338, grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.2503, grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.3820, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 11\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.3157, grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.3085, grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.3102, grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.3280, grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.2790, grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.2935, grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.3451, grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.3458, grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.3211, grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.3037, grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.2893, grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.2898, grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.3058, grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.3460, grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.3106, grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.3094, grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.3276, grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.3235, grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.2931, grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.2603, grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.2330, grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.2867, grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.2650, grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.2736, grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.3285, grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.2745, grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.3125, grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(1.2762, grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.2306, grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(1.3371, grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.3351, grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.3187, grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.2814, grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(1.3147, grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.3007, grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.2700, grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.2505, grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.3079, grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.3393, grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.2702, grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.2749, grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.3159, grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.3214, grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(1.3060, grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.2854, grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.2894, grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.2893, grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.2251, grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.3192, grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.2643, grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.2545, grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.3531, grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.3091, grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.2800, grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.3506, grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.2982, grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.3186, grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.2898, grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.3555, grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.3066, grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.2741, grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.2913, grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.3127, grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.2724, grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.3023, grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.3013, grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.3563, grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.3045, grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.3358, grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.3052, grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.2710, grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.3211, grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.3028, grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.3493, grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.3041, grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.2698, grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.2984, grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.3498, grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.2798, grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(1.2902, grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.3463, grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.3068, grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.3082, grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.3613, grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.3075, grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.2535, grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.3127, grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.3840, grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.3194, grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.3329, grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.2805, grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.2995, grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.3002, grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.3067, grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.2609, grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.3134, grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.2660, grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.2941, grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.3320, grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.2968, grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.2869, grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.2784, grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.3474, grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.2474, grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.3043, grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.2889, grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.3115, grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.2379, grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.2537, grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.2309, grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.3916, grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.3589, grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.3049, grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.3643, grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.2752, grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.2320, grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.2937, grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.3424, grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.2992, grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.2688, grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.2560, grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.2943, grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.3338, grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.2742, grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.2745, grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.2848, grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.2355, grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.2875, grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.2989, grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.3027, grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.2494, grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.3296, grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.2691, grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.2523, grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.2542, grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.3025, grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.2267, grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.2922, grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.3560, grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(1.2645, grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.2920, grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.2613, grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.3086, grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.2649, grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.2899, grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.3827, grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.3025, grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.2891, grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(1.2902, grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.2597, grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.2332, grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.2772, grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.3148, grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.3780, grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.3018, grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.3131, grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.3299, grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.2864, grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.2818, grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.2654, grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.2771, grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.2926, grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.2340, grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.3171, grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.3207, grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.2685, grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.2702, grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.2669, grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.2444, grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.2805, grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.2789, grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.2925, grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.3198, grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.2102, grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.3073, grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.2884, grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.2194, grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.3344, grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.3108, grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.2949, grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.3658, grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.2816, grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.3130, grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.2535, grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.2605, grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.2737, grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.2953, grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.2941, grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.2366, grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.2688, grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.2469, grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.2618, grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.2788, grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.2380, grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.2433, grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.3203, grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.2790, grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.3669, grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.2603, grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.3010, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 12\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.3077, grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.2378, grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.2431, grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.3043, grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.2607, grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.2772, grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.2530, grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.2059, grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.3311, grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.2079, grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.3250, grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.3271, grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.2392, grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.2957, grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.3473, grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.2453, grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.1415, grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.3118, grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.3082, grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.3055, grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.2827, grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.2873, grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.1832, grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.2295, grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.2427, grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.1788, grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.2308, grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(1.2138, grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.2639, grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(1.2627, grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.3237, grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.3009, grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.2958, grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(1.2956, grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.2571, grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.3371, grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.2286, grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.2949, grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.4109, grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.1972, grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.2761, grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.3259, grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.3095, grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(1.3757, grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.3022, grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.2690, grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.2313, grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.3523, grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.1825, grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.2804, grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.2384, grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.2699, grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.2650, grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.3207, grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.2647, grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.2569, grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.2993, grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.3260, grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.2796, grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.2991, grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.2932, grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.2723, grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.2582, grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.3320, grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.2798, grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.3059, grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.2927, grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.2922, grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.2481, grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.2296, grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.3191, grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.2717, grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.3088, grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.2325, grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.3129, grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.2854, grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.2861, grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.3336, grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.2553, grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(1.3080, grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.2903, grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.3092, grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.3577, grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.2936, grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.3186, grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.2838, grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.2440, grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.2982, grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.2397, grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.3253, grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.2533, grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.2622, grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.2905, grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.3205, grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.3124, grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.3087, grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.2473, grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.2666, grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.2154, grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.2694, grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.3706, grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.3599, grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.1984, grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.3129, grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.3332, grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.2967, grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.2266, grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.2834, grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.3062, grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.2758, grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.3397, grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.3206, grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.2245, grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.2940, grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.3014, grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.2679, grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.2983, grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.2865, grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.3119, grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.2069, grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.2402, grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.2669, grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.3204, grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.2635, grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.3042, grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.3330, grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.2477, grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.2218, grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.2704, grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.3607, grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.2860, grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.3102, grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.2836, grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.2580, grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.2827, grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.3067, grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.2700, grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.2566, grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.3174, grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(1.2828, grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.2776, grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.2755, grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.3510, grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.2518, grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.1978, grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.2980, grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.2915, grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.2320, grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(1.2518, grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.3292, grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.2581, grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.2885, grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.2223, grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.3286, grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.2557, grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.2798, grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.2665, grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.2677, grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.2631, grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.2508, grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.3167, grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.3025, grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.2163, grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.2827, grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.3319, grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.3010, grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.2421, grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.2144, grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.3594, grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.2782, grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.2896, grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.1970, grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.2792, grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.3029, grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.2351, grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.2717, grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.2366, grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.3665, grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.2241, grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.2904, grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.2703, grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.1676, grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.2950, grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.2886, grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.3249, grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.3089, grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.2283, grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.1430, grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.3714, grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.3269, grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.2677, grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.2234, grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.2306, grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.2760, grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.3276, grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.2810, grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.2553, grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.2565, grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.2628, grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.2741, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 13\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.3328, grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.2658, grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.2788, grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.2680, grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.2839, grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.2729, grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.2821, grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.2168, grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.2173, grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.2886, grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.2685, grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.2732, grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.2355, grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.2347, grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.3191, grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.2841, grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.2252, grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.2879, grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.2977, grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.2517, grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.2459, grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.3150, grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.3136, grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.3078, grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.2260, grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.3021, grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.2972, grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(1.2895, grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.2597, grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(1.2994, grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.2498, grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.2844, grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.2902, grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(1.3401, grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.2239, grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.2738, grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.2430, grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.2147, grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.2871, grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.3039, grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.2511, grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.2502, grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.2768, grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(1.2873, grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.3055, grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.2513, grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.2938, grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.3284, grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.2807, grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.2351, grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.2155, grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.2774, grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.2867, grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.2704, grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.0969, grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.2336, grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.2510, grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.2940, grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.2889, grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.2085, grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.2706, grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.2717, grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.2647, grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.2399, grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.3431, grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.2537, grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.1840, grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.2479, grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.1946, grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.2380, grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.2927, grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.2620, grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.2351, grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.3124, grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.2322, grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.2034, grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.2325, grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.2801, grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.2192, grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(1.2516, grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.3588, grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.2394, grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.2322, grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.1938, grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.2551, grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.2786, grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.2717, grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.2672, grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.2811, grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.2559, grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.2477, grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.3178, grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.2366, grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.3081, grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.2666, grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.2557, grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.2168, grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.2104, grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.1726, grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.3403, grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.2912, grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.2553, grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.2251, grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.3073, grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.1788, grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.2455, grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.2235, grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.2758, grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.1168, grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.2895, grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.3113, grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.3525, grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.2983, grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.2281, grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.1968, grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.2899, grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.2237, grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.3481, grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.2292, grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.2078, grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.2014, grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.2876, grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.2850, grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.1816, grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.2622, grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.2274, grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.2178, grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.2874, grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.1880, grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.2730, grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.1981, grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.3213, grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.2611, grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.3266, grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.2575, grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.2660, grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.2526, grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.2069, grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.1622, grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(1.2548, grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.3198, grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.2860, grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.3291, grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.1301, grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.2756, grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.2534, grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.2514, grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.2732, grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(1.2860, grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.1939, grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.3198, grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.2350, grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.3058, grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.2235, grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.3384, grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.2429, grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.3264, grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.3034, grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.2549, grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.2218, grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.1782, grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.2722, grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.1881, grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.2437, grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.2864, grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.2678, grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.2356, grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.2432, grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.2751, grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.2954, grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.3388, grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.2501, grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.2285, grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.3019, grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.2479, grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.2902, grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.2777, grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.3245, grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.2582, grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.2102, grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.3384, grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.2732, grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.2129, grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.2396, grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.2269, grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.2449, grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.2078, grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.2486, grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.2838, grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.2255, grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.2164, grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.2363, grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.3210, grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.1412, grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.3246, grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.2476, grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.3318, grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.2614, grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.2123, grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.2904, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 14\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.1887, grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.2968, grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.2138, grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.3704, grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.2133, grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.2477, grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.1868, grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.3034, grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.2397, grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.1677, grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.2792, grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.2486, grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.1777, grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.0735, grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.1514, grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.1743, grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.2578, grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.2498, grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.2873, grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.2554, grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.3534, grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.1792, grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.2127, grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.2439, grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.1501, grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.1499, grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.3172, grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(1.2649, grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.2922, grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(1.2614, grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.2337, grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.1836, grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.2022, grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(1.1922, grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.2780, grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.2507, grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.2675, grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.2049, grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.3348, grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.1772, grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.2992, grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.2079, grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.2859, grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(1.2036, grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.1083, grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.2283, grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.2659, grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.2954, grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.2063, grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.3212, grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.2613, grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.2324, grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.2370, grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.1385, grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.2795, grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.3414, grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.2424, grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.2567, grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.2616, grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.2137, grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.3083, grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.2112, grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.3196, grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.2112, grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.1575, grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.3016, grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.2799, grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.2630, grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.3644, grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.2857, grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.2752, grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.2905, grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.2533, grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.2915, grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.2810, grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.2113, grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.2755, grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.2270, grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.2178, grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(1.3527, grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.2527, grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.1268, grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.2228, grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.3539, grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.2621, grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.2179, grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.1731, grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.2259, grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.2272, grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.2916, grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.2238, grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.1930, grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.1836, grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.1544, grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.2408, grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.2958, grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.2722, grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.2515, grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.2251, grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.2716, grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.2361, grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.2457, grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.2941, grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.2882, grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.2404, grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.1799, grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.2205, grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.1357, grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.2528, grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.3094, grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.2953, grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.2914, grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.1467, grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.3017, grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.2408, grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.2954, grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.2156, grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.2581, grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.2963, grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.2395, grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.2038, grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.2704, grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.2506, grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.2247, grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.1571, grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.0842, grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.2632, grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.2207, grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.2607, grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.1507, grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.2728, grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.1685, grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.1459, grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.2021, grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.1480, grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.0839, grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.2948, grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.2114, grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.1932, grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(1.3074, grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.2671, grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.2046, grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.0982, grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.2012, grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.1735, grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.3066, grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.2445, grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.2047, grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(1.3148, grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.2389, grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.3302, grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.2564, grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.2287, grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.2420, grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.3122, grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.3248, grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.1831, grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.2267, grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.2703, grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.1707, grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.2473, grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.2083, grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.2968, grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.2313, grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.1946, grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.1773, grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.3020, grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.3597, grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.2307, grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.3223, grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.1956, grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.1985, grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.2469, grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.1855, grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.1655, grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.3034, grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.2894, grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.2958, grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.2533, grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.1850, grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.2065, grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.2837, grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.3043, grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.3046, grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.2528, grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.2709, grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.1336, grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.1751, grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.2194, grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.2828, grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.2121, grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.2409, grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.2932, grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.3482, grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.1982, grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.2633, grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.2439, grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.2409, grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.2103, grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.2672, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 15\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.2131, grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.2035, grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.2863, grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.2809, grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.2406, grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.2178, grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.1663, grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.3065, grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.2479, grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.2274, grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.1474, grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.1435, grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.1022, grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.3914, grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.2728, grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.2524, grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.2743, grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.2708, grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.1878, grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.2455, grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.2822, grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.1873, grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.2055, grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.2669, grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.2498, grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.1615, grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.2079, grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(1.2403, grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.2045, grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(1.2168, grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.2343, grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.2379, grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.2907, grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(1.2292, grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.3602, grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.2362, grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.1793, grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.2861, grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.2886, grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.2492, grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.0849, grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.3017, grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.2373, grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(1.1412, grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.2680, grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.1699, grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.2420, grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.1694, grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.2551, grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.2327, grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.1618, grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.2336, grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.1978, grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.2624, grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.2312, grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.3191, grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.1371, grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.1549, grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.2695, grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.3612, grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.1718, grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.1819, grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.2100, grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.2786, grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.2557, grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.1338, grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.2257, grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.2368, grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.1898, grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.1980, grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.2649, grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.1963, grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.1129, grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.2092, grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.1209, grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.2992, grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.1581, grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.1244, grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.1651, grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(1.2513, grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.1778, grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.2283, grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.2459, grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.3102, grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.2290, grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.2403, grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.2517, grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.3283, grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.1438, grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.2946, grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.2093, grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.1354, grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.1933, grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.2940, grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.2789, grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.2373, grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.2372, grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.2767, grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.2449, grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.1733, grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.2047, grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.3356, grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.2703, grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.1775, grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.2641, grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.2267, grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.1722, grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.2606, grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.2073, grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.3077, grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.1655, grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.1271, grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.2242, grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.2129, grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.3392, grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.3143, grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.2365, grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.2889, grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.1173, grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.1937, grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.1537, grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.2496, grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.1688, grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.2014, grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.1300, grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.1704, grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.2554, grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.2818, grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.3267, grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.2460, grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.2620, grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.2003, grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.2315, grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.1589, grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.2179, grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.2919, grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.2233, grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.1225, grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.1814, grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(1.2309, grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.2119, grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.2396, grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.2376, grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.2007, grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.2109, grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.1917, grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.2468, grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.2350, grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(1.2974, grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.0964, grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.1850, grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.0883, grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.1336, grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.2331, grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.2079, grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.2499, grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.3230, grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.1006, grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.0635, grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.2520, grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.1421, grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.1661, grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.2440, grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.1191, grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.3824, grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.2509, grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.1360, grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.3237, grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.0848, grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.2872, grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.3168, grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.2322, grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.1067, grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.0858, grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.1547, grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.2277, grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.1078, grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.1999, grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.1660, grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.2569, grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.1881, grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.1979, grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.1346, grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.2144, grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.2551, grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.2917, grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.2431, grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.1142, grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.1447, grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.2469, grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.2377, grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.1319, grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.2338, grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.1895, grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.2402, grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.2411, grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.3305, grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.2786, grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.2035, grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.3100, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 16\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.1283, grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.1886, grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.1831, grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.1923, grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.3104, grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.1450, grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.2597, grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.2165, grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.2186, grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.0968, grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.1967, grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.2467, grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.1021, grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.2495, grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.1736, grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.0646, grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.2631, grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.1959, grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.1896, grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.1471, grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.2148, grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.2619, grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.2443, grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.1825, grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.1868, grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.2131, grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.1891, grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(1.2210, grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.2211, grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(1.1560, grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.2338, grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.2053, grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.2319, grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(1.2447, grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.1124, grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.2110, grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.1429, grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.1531, grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.0898, grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.1141, grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.2223, grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.2643, grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.1659, grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(1.1265, grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.2979, grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.1889, grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.1438, grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.1396, grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.3016, grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.1446, grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.2576, grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.1376, grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.2654, grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.2527, grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.2492, grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.2428, grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.2094, grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.0464, grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.1896, grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.3077, grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.2458, grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.3459, grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.0968, grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.1694, grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.1886, grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.3301, grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.1532, grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.1746, grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.1457, grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.2237, grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.2050, grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.0690, grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.2067, grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.2022, grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.1146, grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.2442, grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.1599, grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.1885, grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.2461, grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(1.2931, grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.1538, grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.1690, grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.2969, grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.1560, grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.1906, grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.1751, grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.2180, grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.2507, grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.3095, grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.2376, grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.1256, grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.1789, grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.2634, grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.1800, grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.3121, grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.2148, grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.2971, grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.3532, grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.1586, grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.2780, grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.2757, grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.0415, grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.2207, grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.2014, grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.1268, grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.1960, grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.1851, grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.1254, grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.1876, grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.1804, grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.1072, grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.3322, grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.3320, grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.2426, grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.0606, grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.2248, grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.0974, grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.2608, grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.2859, grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.1941, grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.1225, grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.2736, grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.3217, grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.1985, grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.2275, grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.2634, grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.1074, grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.1790, grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.1774, grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.2594, grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.1652, grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.1981, grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.0972, grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.2804, grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.1253, grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.2621, grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.1478, grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.2486, grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.1403, grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(1.1436, grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.0609, grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.2294, grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.1002, grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.1069, grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.2365, grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.1978, grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.2345, grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.1770, grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(1.2512, grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.1679, grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.1751, grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.1335, grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.1796, grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.1287, grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.1539, grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.0243, grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.1759, grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.2805, grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.1210, grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.1229, grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.3096, grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.2236, grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.1498, grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.2026, grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.1112, grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.2385, grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.1991, grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.1235, grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.2018, grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.2552, grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.2207, grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.2119, grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.2214, grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.0168, grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.3437, grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.2820, grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.3256, grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.2233, grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.0717, grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.0990, grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.3115, grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.2842, grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.0465, grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.1466, grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.2531, grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.1922, grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.1354, grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.1410, grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.2707, grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.2349, grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.2084, grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.3121, grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.2715, grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.1410, grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.2032, grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.1539, grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.3158, grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.2960, grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.2319, grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.1196, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 17\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.2735, grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.1664, grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.1725, grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.1059, grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.2217, grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.1049, grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.1975, grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.2099, grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.2799, grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.1009, grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.2397, grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.2091, grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.1393, grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.0938, grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.2629, grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.2913, grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.0911, grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.0674, grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.2086, grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.1969, grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.1958, grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.3091, grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.2759, grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.0917, grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.2533, grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.1785, grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.1738, grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(1.2386, grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.1848, grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(1.1363, grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.2561, grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.1499, grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(0.9907, grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(1.3689, grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.1870, grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.2262, grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.2674, grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.0326, grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.2119, grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.1317, grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.1660, grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.1355, grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.2384, grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(1.2239, grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.1124, grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.2980, grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.0737, grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.1682, grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.1171, grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.1175, grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.2929, grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.2080, grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.1796, grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.1548, grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.1549, grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.2829, grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.1527, grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.1509, grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.1942, grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.1980, grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.1480, grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.1979, grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.2469, grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.3345, grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.1676, grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.1865, grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.1734, grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.2288, grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.1559, grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.1369, grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.2404, grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.0498, grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.0992, grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.2033, grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.2683, grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.0859, grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.1200, grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.1802, grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.0407, grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(1.2517, grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.0445, grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.0469, grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.2420, grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.2056, grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(0.9975, grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.1576, grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.1929, grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.1718, grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.1928, grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.1668, grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.1758, grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.2852, grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.2069, grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.1747, grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.2679, grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.1440, grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.2422, grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.1178, grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.1289, grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.2989, grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.1508, grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.2558, grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.2920, grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.1627, grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.1590, grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.1364, grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.2381, grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.1698, grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.2152, grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.1611, grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.0857, grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.2132, grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.1158, grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.1389, grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.2733, grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.2135, grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.0839, grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.2449, grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.0656, grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.1268, grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.1411, grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.1144, grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.1007, grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.0431, grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.4068, grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.1050, grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.1749, grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.1950, grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.1679, grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.1617, grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.1313, grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.3065, grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.2315, grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.1620, grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.1349, grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.2872, grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.1392, grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.2177, grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.1281, grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(1.2176, grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.2049, grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.2079, grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.1636, grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.2093, grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.1554, grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.1576, grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.2548, grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.2066, grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(1.1878, grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.2178, grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.2818, grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.2175, grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.1210, grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.2102, grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.0478, grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.2716, grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.2005, grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.2439, grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.0388, grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.2521, grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.0691, grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.2709, grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.1700, grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.1150, grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.1057, grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.1235, grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.1228, grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.3218, grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.0222, grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.1999, grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.1697, grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.2114, grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.0783, grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.1324, grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.0561, grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.0434, grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.0902, grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.0616, grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.2582, grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.1645, grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.1351, grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.3604, grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.2006, grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.1267, grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.2603, grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.1545, grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.2515, grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.1461, grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.0716, grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.2154, grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.2968, grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.2986, grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.0396, grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.1920, grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.1615, grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.1060, grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.0778, grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.2830, grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.1056, grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.1645, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 18\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.1993, grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.1266, grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.1527, grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.1198, grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.1492, grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.2230, grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.0774, grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.0850, grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.1883, grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.2798, grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.2276, grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.1583, grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.2043, grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.1955, grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.0962, grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.0534, grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.2393, grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.3247, grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.1868, grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.1536, grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.2493, grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.0550, grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.2096, grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.1173, grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.2019, grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.1816, grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.0784, grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(1.0660, grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.1630, grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(1.1072, grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.1937, grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.2950, grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.0361, grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(1.1183, grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.0295, grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(0.9279, grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.0024, grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.2362, grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.1550, grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.0614, grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.1999, grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.2060, grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.1656, grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(1.0139, grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.0278, grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.1600, grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.3249, grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.2793, grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.0603, grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.1573, grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.2106, grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.0335, grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.0996, grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.0145, grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.0392, grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.1028, grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(0.9992, grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.1197, grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.0273, grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.2072, grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.3043, grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.0559, grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.1980, grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.2675, grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.0693, grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.1284, grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.1540, grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.1928, grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.1361, grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.2277, grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.2549, grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.1365, grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.0970, grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.0080, grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.1387, grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.2228, grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.1390, grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.2034, grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.0346, grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(1.1894, grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.0755, grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.2048, grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.1377, grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.0160, grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.2758, grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.2069, grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.1974, grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.3060, grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.0540, grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.1532, grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.0569, grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.1272, grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.2632, grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(0.9986, grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.1411, grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.1392, grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.1784, grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.1862, grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(0.9211, grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.2633, grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.1240, grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.2111, grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.0038, grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.1679, grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.1662, grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.1438, grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.2578, grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.0145, grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.4241, grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.1460, grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.0572, grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.0794, grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.2057, grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.2292, grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.1950, grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.2092, grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.1999, grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.0738, grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.1854, grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.0026, grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.2430, grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.1894, grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.1150, grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.1658, grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.4049, grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.1522, grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.1276, grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.1657, grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.2081, grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.2857, grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.0864, grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.1368, grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.3120, grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.2600, grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.1477, grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.0590, grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.1552, grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.1761, grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.1409, grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(1.0503, grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.1225, grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.2617, grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.2710, grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.1589, grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.1000, grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.2151, grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.2150, grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.1943, grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(1.2014, grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.0593, grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(0.9986, grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.2190, grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.0907, grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.2150, grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.1441, grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.1210, grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.1730, grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.1833, grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.2194, grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.2802, grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.1645, grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.0613, grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.1916, grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.1624, grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.2035, grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.0917, grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.0379, grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.2895, grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.1542, grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.1513, grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.1399, grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.0905, grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.2204, grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.1839, grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.0373, grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.1694, grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.1268, grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.2105, grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.2071, grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.2106, grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.2202, grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.1113, grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.1514, grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.1247, grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(0.9847, grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.2520, grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.1276, grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.0697, grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.1194, grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.1402, grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.0622, grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.2289, grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.1457, grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.3349, grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.1338, grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.1576, grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.0519, grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.1300, grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.0261, grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.2612, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 19\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.2018, grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.0570, grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.2628, grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.1497, grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.0684, grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.1082, grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.0159, grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.1026, grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.1916, grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.3567, grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(0.9760, grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.2258, grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.0730, grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.0739, grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.1956, grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.1582, grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.1298, grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.1511, grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.1025, grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.0784, grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.1355, grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.1945, grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.2809, grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.1828, grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.0473, grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.1875, grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.0923, grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(1.2675, grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.1738, grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(1.1512, grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.1807, grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.1785, grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.0751, grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(0.9864, grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.0311, grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.2422, grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.1563, grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.0014, grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.2437, grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.1493, grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.2200, grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.2056, grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.1082, grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(1.1339, grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.1987, grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.1987, grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.0761, grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.1817, grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.1514, grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.0966, grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(0.9605, grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.2407, grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.0902, grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.1899, grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.1751, grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.2412, grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(0.9992, grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.1364, grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.0501, grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.0803, grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.0625, grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.0929, grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.2261, grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.2094, grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.1242, grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.0834, grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.1301, grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.1522, grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.1937, grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.0045, grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.0516, grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.0428, grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.2045, grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.1879, grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.0550, grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.1419, grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.3254, grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.1604, grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.1066, grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(1.1201, grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.1562, grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.0676, grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.1554, grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.2743, grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.1855, grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.1667, grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.0506, grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.2346, grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.1334, grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.2017, grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.1781, grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(0.9616, grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.0059, grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.2006, grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.3322, grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.1609, grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.2041, grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.2798, grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.1876, grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.1248, grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.1516, grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.2220, grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.1922, grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.1021, grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.0505, grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.1024, grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.2033, grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.1184, grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.0191, grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.0699, grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.2516, grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.0547, grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.0980, grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.0476, grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.1920, grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.1033, grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.0524, grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.2356, grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.1032, grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.2534, grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.0335, grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.1706, grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.1449, grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(0.9838, grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.0954, grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.1676, grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.0481, grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.2683, grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.2155, grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.0718, grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.1786, grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.1815, grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.0177, grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(0.9191, grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(0.9980, grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.1576, grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.0425, grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.0034, grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.1364, grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(1.2060, grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.1076, grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.1099, grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.1563, grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.1774, grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.0450, grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.0758, grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.0389, grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.0881, grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(1.3105, grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.1262, grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.2250, grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.0497, grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.0815, grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.0199, grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.1683, grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.1943, grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(0.9515, grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.2010, grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.1613, grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.0630, grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.1287, grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.0366, grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.2160, grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.1656, grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(0.9775, grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.0795, grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.1029, grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.2514, grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.1565, grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.2831, grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.2267, grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.2113, grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.0785, grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.1725, grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.1611, grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.1728, grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.0868, grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.2312, grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(0.9253, grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.1413, grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.1744, grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.3125, grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.0321, grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.0333, grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.1790, grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.1281, grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.1307, grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.2819, grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.1323, grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.0689, grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.1201, grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.1152, grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.2121, grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.0284, grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.2906, grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(0.9877, grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.3117, grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.1521, grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.1136, grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.1061, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 20\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.0729, grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.1304, grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.1874, grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.1273, grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.0674, grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.0470, grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.2806, grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.1832, grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.1207, grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.1439, grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.3120, grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.0393, grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.0869, grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.2260, grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(0.9893, grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.1009, grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.0992, grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.1925, grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.0227, grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.3211, grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.1013, grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.0536, grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.1596, grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.1889, grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.1669, grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.0977, grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.0339, grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(1.1211, grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.0388, grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(0.9978, grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.1343, grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.1701, grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.1486, grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(0.9944, grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.1731, grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.0576, grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.2307, grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.1502, grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.1431, grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.0828, grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.0248, grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.2505, grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(0.8317, grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(1.1559, grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(0.8954, grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(0.9556, grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.1409, grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.1946, grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.1706, grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.1908, grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.0343, grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.1175, grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.0657, grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(0.8757, grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.0520, grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.1684, grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.1225, grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.1085, grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.0539, grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.0734, grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.1526, grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.4271, grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.1437, grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.1996, grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.0375, grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(0.9983, grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.0744, grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.1378, grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.1712, grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.1651, grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.1278, grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.1049, grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(0.9765, grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.2694, grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.1849, grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(0.9346, grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.0952, grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.1964, grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.0684, grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(1.0493, grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.1150, grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.1003, grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.0695, grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.1009, grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.1849, grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.1026, grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.1540, grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.1997, grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.3211, grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.0587, grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.3034, grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.1911, grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.2536, grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(0.8568, grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.0311, grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.1317, grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.0164, grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.0541, grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.0452, grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.1622, grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.1045, grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.2101, grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.3412, grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.0115, grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.1057, grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.1309, grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.0909, grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.3134, grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.1837, grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.0641, grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.1257, grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.2312, grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(0.9799, grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(0.9532, grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.0654, grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(0.8820, grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.0755, grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.3202, grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.3414, grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(0.9894, grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.0354, grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.0692, grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.1548, grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.0903, grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.2794, grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.1725, grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.0692, grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.2132, grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.0052, grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.1742, grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.1280, grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.0830, grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.1455, grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.0953, grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.0476, grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.3380, grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.0420, grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.2437, grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.3403, grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(1.1030, grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.1945, grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.1034, grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.1236, grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.1427, grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.1338, grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.1140, grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(0.9383, grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.0666, grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(1.1917, grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.1778, grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.0800, grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.0105, grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(0.9547, grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.1370, grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.0342, grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(0.9883, grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.1979, grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.1054, grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.2613, grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.1170, grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.1107, grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.2623, grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.1199, grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.0920, grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.1135, grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.1483, grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.1141, grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.2525, grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(0.9737, grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.0734, grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(0.9395, grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.1162, grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.1437, grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.1074, grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.1034, grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.0729, grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(0.9484, grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.0097, grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.0825, grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.1940, grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.0568, grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.1989, grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.1822, grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.0797, grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.2022, grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.1357, grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.0361, grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.1576, grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.1771, grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.1391, grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.0748, grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.0138, grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.2497, grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.2463, grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.0608, grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.2133, grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.0593, grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.0691, grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.2450, grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.0338, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 21\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.1300, grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.0865, grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(0.9251, grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.0409, grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.2091, grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.0162, grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.0935, grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.0532, grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.1356, grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.2599, grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(0.8510, grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.2575, grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.1146, grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.0330, grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.1873, grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.0864, grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.0739, grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.1235, grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.1884, grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.0569, grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(0.9813, grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(0.8595, grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.0698, grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.0477, grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.1321, grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.0829, grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(0.9444, grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(1.2885, grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.0333, grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(1.0872, grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.1346, grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.0919, grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(0.8925, grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(1.1169, grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.2178, grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.1986, grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.3067, grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.1757, grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.0357, grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.2981, grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.2273, grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.2610, grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(0.9887, grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(1.1629, grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.1299, grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.1484, grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.0079, grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.0116, grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.2136, grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.0834, grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.1527, grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.0551, grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.1301, grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.0855, grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.2635, grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.1847, grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.1855, grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.1766, grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.0886, grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.1351, grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(0.9532, grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.3354, grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.1127, grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.2148, grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.0480, grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.1269, grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.0563, grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(0.9569, grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.0869, grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.0836, grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.0753, grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.1313, grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.2941, grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.0501, grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(0.9500, grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.0457, grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.1229, grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.1603, grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.1667, grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(1.1900, grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.0882, grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.1283, grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.1021, grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.0469, grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.0492, grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(0.9322, grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.1336, grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.1857, grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.0701, grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.1450, grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.0528, grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.2342, grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.0001, grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.1574, grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(0.9856, grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.1331, grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(0.9701, grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.2009, grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.0556, grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.1186, grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.0116, grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.0730, grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.0919, grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.1485, grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(0.9804, grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(0.9476, grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.0554, grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.1846, grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.2238, grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.1092, grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(0.8082, grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.1644, grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.1467, grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.2478, grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.0842, grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.2600, grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.0654, grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.1063, grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.0774, grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.1040, grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.2155, grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(0.9663, grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.0883, grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.0666, grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(0.9385, grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.3294, grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(0.9779, grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.0729, grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.3294, grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.1398, grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.0403, grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(0.8907, grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.1383, grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.0209, grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.1065, grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.1545, grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.1821, grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.0143, grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.0240, grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(1.3256, grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.1688, grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.1963, grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.1334, grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.2554, grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.1169, grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.1014, grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.1327, grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(0.9135, grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(1.0979, grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.0030, grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(0.9915, grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.2030, grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.0605, grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.1211, grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(0.9820, grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.3367, grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.1088, grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.1350, grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.2081, grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.0114, grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(0.8972, grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(0.9441, grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.2152, grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.2117, grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.0801, grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.0312, grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.0750, grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.0545, grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.0667, grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.1006, grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(0.9719, grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.0155, grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(0.9597, grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(0.9779, grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.1421, grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.2616, grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.0230, grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.0520, grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.1845, grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.1812, grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(0.9943, grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.0006, grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.0763, grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.1736, grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.0989, grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.1711, grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.0961, grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.2412, grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.0796, grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.1514, grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(0.9951, grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.0042, grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.1050, grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(0.9860, grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.1941, grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.0108, grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.1974, grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.1174, grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(0.9920, grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(0.8630, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 22\n",
            "================\n",
            "Batch No 0,\tloss is tensor(0.9753, grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.1751, grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(0.9957, grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(0.9776, grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.0301, grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.2258, grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.1662, grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.0021, grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.0811, grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(0.9753, grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(0.9927, grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(0.8099, grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(0.9794, grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.2007, grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.0360, grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(0.9600, grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(0.9920, grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.1542, grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.2173, grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(0.9834, grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.1644, grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.2143, grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.1515, grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(0.9948, grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(0.9319, grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.2171, grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(0.9884, grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(1.2419, grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.1604, grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(1.2133, grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(0.9743, grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.1718, grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.1758, grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(1.2097, grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.0552, grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.0228, grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.2223, grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.1808, grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.1535, grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.1171, grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.0045, grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.1952, grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.2028, grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(1.0194, grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.1150, grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.0651, grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.0416, grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.1816, grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.1309, grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.1648, grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.1790, grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.2608, grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.2015, grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.1107, grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.1419, grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.1694, grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.1899, grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.1116, grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.1577, grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.0972, grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.0493, grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.0721, grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.0396, grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.1546, grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.0769, grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(0.9129, grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.1287, grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.0577, grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(0.9582, grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(0.9300, grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(0.9666, grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(0.9849, grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.2364, grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.1951, grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.0612, grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.1614, grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.1048, grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(1.0914, grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.1715, grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.1701, grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(0.9957, grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.0053, grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.1588, grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.1473, grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(0.9996, grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(0.9995, grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.3022, grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.0660, grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.0184, grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(0.9914, grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.2509, grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(0.9727, grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.0282, grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.0854, grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.1052, grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(0.9699, grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(0.8373, grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.1189, grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.1828, grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.2863, grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(0.9498, grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.1186, grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.0259, grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(0.9692, grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.0795, grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.0745, grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.0013, grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.1440, grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(0.9224, grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.3367, grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(0.9967, grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.1950, grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.2330, grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.0915, grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.1930, grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(0.9784, grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(0.9424, grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.2409, grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(0.9909, grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.0729, grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.0412, grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.0407, grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.2161, grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.1835, grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.0283, grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(0.9695, grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.0547, grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.1248, grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(0.9629, grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.2760, grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(0.8932, grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.0653, grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.1284, grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.0614, grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.1783, grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.0485, grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.0850, grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(1.0723, grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.0747, grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(0.9443, grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.0660, grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.3303, grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.0354, grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(0.9563, grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.1928, grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.0848, grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(1.0354, grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.1062, grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(0.9576, grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.1268, grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.0748, grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.0777, grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.0728, grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.1120, grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.0766, grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.1816, grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.2957, grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.1625, grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.1424, grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(0.9896, grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.0491, grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.0388, grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.1760, grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(0.9541, grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(0.9543, grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.1036, grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.1049, grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(0.9914, grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.1995, grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(0.9550, grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(0.9834, grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(0.9275, grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.2414, grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.0275, grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.0609, grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.0130, grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(0.9331, grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.0591, grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.2240, grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.2219, grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.1024, grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(0.8722, grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.1601, grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.2024, grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.0850, grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.0653, grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.1743, grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.2430, grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.1230, grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.2908, grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.0507, grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.0178, grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.0761, grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.0492, grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.0790, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 23\n",
            "================\n",
            "Batch No 0,\tloss is tensor(0.9929, grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.1574, grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(0.8473, grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.0905, grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.2017, grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(0.9554, grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.1786, grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.1861, grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.1597, grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.0287, grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.0231, grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.1931, grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.0590, grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.0696, grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.1125, grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.0010, grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.1601, grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.1114, grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.0269, grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(0.9458, grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.0537, grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.1124, grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.0562, grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.2545, grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(0.9556, grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.2139, grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.0412, grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(1.0704, grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.1156, grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(0.9406, grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.1743, grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(0.9838, grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.0505, grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(1.2643, grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(0.9204, grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.0254, grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(0.8197, grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(0.9086, grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(0.9700, grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.2549, grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.0098, grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(0.9695, grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.0497, grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(0.9753, grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.0447, grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(0.9778, grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(0.8223, grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.2319, grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(0.9896, grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(0.9878, grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.1047, grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.1444, grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(0.9417, grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.0683, grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.1872, grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.1513, grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.2224, grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(0.9817, grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(0.8648, grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.0430, grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.0903, grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(0.9998, grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.1294, grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.0507, grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.2289, grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.0730, grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(0.8648, grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.0488, grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(0.9622, grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.1979, grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.2013, grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(0.8796, grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.0536, grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.0202, grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(0.8573, grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.0895, grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(0.9784, grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(0.9015, grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.0177, grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(1.1073, grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.2041, grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.1047, grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.2274, grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.0732, grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.2740, grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.1151, grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.1247, grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.0440, grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(0.9789, grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.1423, grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(0.9832, grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.0754, grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.1472, grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(0.9465, grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.1433, grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.0998, grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.1001, grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.3511, grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(0.9811, grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.1069, grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.0635, grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(0.9761, grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.0887, grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.1135, grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.1440, grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.1306, grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.1290, grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(0.9904, grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.1263, grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.0645, grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.0374, grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.0469, grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.0183, grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(0.9346, grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.0833, grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.1981, grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.1649, grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(0.9759, grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.2229, grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.1562, grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(0.9961, grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.1919, grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.2225, grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.0349, grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.1590, grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.1517, grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.0439, grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.1554, grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.0355, grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(0.9124, grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.1737, grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(0.9829, grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.0394, grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.0361, grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.0492, grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.0959, grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.0824, grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.0511, grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.0973, grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(1.0679, grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.0110, grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.2118, grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(0.8970, grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.0197, grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(0.9892, grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(0.8739, grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.1020, grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.2351, grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(0.9500, grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.2127, grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.2230, grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.0999, grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.0546, grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(0.9701, grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.1846, grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.0020, grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.2434, grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.2624, grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.0916, grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(0.8733, grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(0.9748, grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.0532, grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.0284, grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(0.8427, grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(0.9816, grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(0.9714, grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.1596, grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.1942, grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(0.9507, grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.0727, grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.3200, grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.0734, grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.0719, grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.0446, grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(0.9769, grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.0089, grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(0.9964, grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.0688, grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.0413, grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.1836, grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.0829, grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(0.9396, grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.1008, grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.0352, grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.2233, grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(0.9375, grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.2018, grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(0.9657, grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.1323, grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(0.8002, grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(0.9930, grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.2504, grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.1669, grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.1440, grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.0045, grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(0.8928, grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.0939, grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.1557, grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.1179, grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.0900, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 24\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.0352, grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.0874, grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.0742, grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.0562, grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.1781, grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.1068, grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(0.9827, grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.2006, grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.2000, grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.1089, grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.0891, grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.0408, grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(0.9908, grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.0586, grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(0.9935, grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.1084, grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.1486, grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.1831, grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.0419, grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.0805, grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.0143, grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.0886, grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.1292, grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.0725, grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.1110, grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.0651, grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.0264, grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(1.1063, grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(1.1658, grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(0.9939, grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(0.9425, grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.0264, grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(1.1156, grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(0.9068, grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.0986, grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(0.9317, grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.1568, grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(0.8860, grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.0837, grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(0.9872, grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(0.9600, grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(0.9904, grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(1.1864, grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(0.9886, grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(0.8267, grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(0.9004, grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(0.9328, grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(0.9135, grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(0.9944, grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(0.9063, grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(0.9501, grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(0.9359, grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.1035, grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.1234, grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.0931, grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.0991, grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.0832, grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(0.9540, grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.1179, grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(0.8839, grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.0932, grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.0614, grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.1427, grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.1295, grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.0684, grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.0668, grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.1017, grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.0690, grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.0576, grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.0445, grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.0937, grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.0342, grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(0.9604, grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.0082, grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.0487, grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(0.9925, grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.0426, grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.1531, grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(0.8934, grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.1257, grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(0.8250, grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.0192, grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(0.9883, grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.2133, grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.1656, grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.1215, grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.0249, grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.4887, grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.1420, grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.0950, grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.0267, grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.0610, grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.0277, grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.0287, grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.0105, grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(0.8325, grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.1817, grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.2049, grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.0001, grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.2067, grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.0456, grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.0539, grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(0.9404, grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.0689, grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(0.9813, grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(0.8389, grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.3214, grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.0149, grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.2323, grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.1023, grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(0.9712, grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.2223, grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(0.9993, grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.1961, grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(0.9906, grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(0.9089, grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.1305, grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.2995, grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.1539, grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(0.9318, grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.0688, grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.0503, grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.1658, grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(0.9443, grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.0709, grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.0967, grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.0111, grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.1375, grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.3308, grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(0.8826, grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(0.9749, grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.1738, grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.2922, grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.2325, grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.1245, grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.0512, grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(0.7727, grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.2067, grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(0.9234, grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(0.9731, grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.0066, grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.0195, grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(0.9161, grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.0506, grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.1134, grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.1903, grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(0.8165, grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(1.0640, grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(0.9574, grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.1183, grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(0.9189, grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(0.8444, grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.1361, grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(0.9858, grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.1304, grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.2183, grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(0.9815, grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.0356, grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(0.8172, grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(0.9628, grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.3158, grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.0734, grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.2865, grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.0671, grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.2452, grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(0.9867, grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.1594, grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.0631, grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.4335, grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(0.8754, grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.1114, grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.1306, grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.0978, grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(0.8525, grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.1761, grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.0011, grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(0.9050, grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(0.8825, grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.1364, grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.0394, grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.2220, grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(0.8827, grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.0521, grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(0.9659, grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.2259, grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(0.9667, grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.0735, grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.2366, grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.0284, grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.1221, grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.1215, grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(0.9367, grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.0599, grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.0706, grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.2184, grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.0997, grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(0.9957, grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(0.8905, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 25\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.1565, grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.2120, grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.0993, grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.0676, grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(0.9530, grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(0.9445, grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.0134, grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.1224, grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(0.8709, grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(0.9121, grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.1773, grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.0382, grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(0.9210, grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.2166, grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.1270, grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(0.8796, grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.0290, grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.0855, grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.1206, grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.2227, grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.0135, grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.0117, grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.0450, grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.2378, grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(0.8927, grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.0704, grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.3964, grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(0.7632, grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.0358, grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(1.0238, grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.2088, grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.0540, grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.1604, grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(0.9251, grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.0274, grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.1085, grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.0961, grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(0.8490, grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.0268, grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.3162, grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(0.9643, grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.1014, grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(0.9149, grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(1.0379, grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.0672, grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.0386, grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.0055, grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.1160, grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.0100, grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(0.9291, grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(0.8879, grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(0.9223, grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(0.9946, grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.2223, grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.0023, grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(0.9528, grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(0.9600, grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.0986, grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.0094, grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(0.9646, grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.0936, grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(0.8775, grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.0201, grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(0.8602, grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.2961, grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.1436, grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(0.9769, grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(0.9889, grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.2366, grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.1686, grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(0.9513, grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.0311, grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.1114, grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.0364, grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(0.9700, grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(0.9807, grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(0.9905, grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(0.9781, grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(0.7850, grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(0.9060, grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(0.8789, grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.1436, grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.2247, grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.2068, grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.0078, grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.2128, grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.2878, grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(0.9927, grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(0.8832, grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.1476, grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.1560, grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.0511, grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.0989, grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.0430, grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(0.9997, grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.0282, grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.0497, grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(0.8782, grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.0951, grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.4459, grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.0149, grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(0.9868, grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.0153, grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(0.9060, grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(0.8832, grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(0.8777, grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.0776, grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(0.9256, grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.0293, grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(0.9548, grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.1009, grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.0269, grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.1835, grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(0.8967, grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.1063, grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.1651, grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.1412, grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(0.9677, grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.0859, grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.4013, grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.2616, grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.2271, grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.1823, grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.1457, grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.0096, grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(0.9969, grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(0.9903, grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(0.9957, grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.1367, grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(0.9390, grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.0077, grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(0.9393, grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(0.9130, grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(0.8668, grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.1400, grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(0.9643, grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(0.9475, grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(0.9683, grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(0.9714, grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.0288, grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.1403, grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(0.9510, grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.1564, grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(0.9912, grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(0.8521, grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.1761, grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(0.7364, grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(0.8603, grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.1199, grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.0889, grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(0.9911, grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(0.9004, grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.0306, grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.2281, grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.1820, grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.1937, grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.0986, grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.0825, grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.0652, grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(0.8986, grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.0898, grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.2726, grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.1269, grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.2248, grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(0.9083, grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(0.9201, grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.0603, grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(0.9876, grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.3165, grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.1279, grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.0120, grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.0911, grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.1131, grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.0469, grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(0.8507, grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.0125, grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(0.8912, grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.0173, grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.0424, grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.0983, grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(0.9098, grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(0.9979, grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(0.8244, grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.3501, grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.0877, grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.0867, grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.2447, grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(0.9340, grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(0.9721, grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(0.9511, grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.1058, grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.1222, grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.0802, grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.0463, grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.0295, grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.0317, grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.0206, grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.0648, grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(0.8016, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 26\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.0446, grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.3590, grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(0.9058, grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(0.9194, grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.1300, grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(0.8743, grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.2330, grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.0568, grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(0.9417, grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(0.8973, grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.0635, grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.0201, grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(0.9482, grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(0.9727, grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(0.8562, grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.2232, grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(0.8258, grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(0.9535, grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.0741, grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(0.9927, grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(0.8821, grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.0209, grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(0.8511, grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(0.9643, grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.0327, grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.0295, grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.0563, grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(1.2647, grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.1872, grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(0.9961, grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(0.9451, grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(0.9337, grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(0.8687, grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(1.0167, grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.1389, grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.1616, grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.1010, grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(0.9830, grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(0.9472, grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.0038, grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.1902, grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.1663, grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.2084, grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(1.2773, grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(0.9983, grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.2404, grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.1267, grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.1354, grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.0777, grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.0262, grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.1869, grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(0.8604, grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.0654, grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.0554, grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.1379, grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.0673, grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.2239, grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.1146, grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.0057, grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.2121, grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.1089, grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(0.9927, grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(0.8875, grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.0537, grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(0.8968, grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.1403, grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(0.9892, grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(0.8721, grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.0283, grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.1642, grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.0475, grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.2207, grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.1384, grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(0.8795, grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(0.9562, grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.1053, grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.0992, grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(0.9889, grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(0.8263, grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.2402, grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.0879, grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.1877, grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(0.9606, grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.0261, grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.1239, grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.0677, grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.2029, grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.0646, grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.0914, grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.0575, grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(0.9768, grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(0.8784, grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.0183, grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(0.9482, grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.1740, grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.0378, grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.1333, grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.0735, grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(0.9979, grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(0.8463, grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(0.9622, grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.2655, grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.1134, grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.1350, grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.2241, grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.2689, grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(0.7567, grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(0.9759, grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(0.9348, grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(0.9406, grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(0.9627, grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.0092, grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(0.8599, grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(0.8843, grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.2712, grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.3303, grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(0.9300, grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(0.9582, grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.0344, grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(0.9314, grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(0.8690, grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(0.8867, grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(0.9970, grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(0.9831, grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.2939, grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.1778, grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.3017, grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.0043, grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(0.9714, grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.3120, grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(0.9870, grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.2157, grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(0.8517, grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(0.8133, grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(0.9589, grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.0147, grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.0344, grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(1.2083, grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.2592, grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.1026, grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(0.9487, grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.1447, grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(0.8826, grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.1947, grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.2244, grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.4263, grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(0.8818, grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(0.8198, grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.2433, grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.2438, grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.0592, grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(0.8362, grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.1044, grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.0059, grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.0749, grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(0.8729, grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.0744, grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.1025, grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(0.9731, grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(0.9510, grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(0.9539, grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(0.7877, grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(0.9652, grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.1044, grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.0772, grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(0.7844, grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(0.9650, grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(0.9883, grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(0.7797, grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.0326, grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(0.8111, grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(0.9650, grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(0.5530, grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.0048, grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.0067, grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.0347, grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.2197, grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.2790, grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.1984, grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(0.8477, grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.0745, grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(0.9302, grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.0929, grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(0.8591, grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(0.8948, grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.0760, grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(0.9946, grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.1398, grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.0520, grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(0.8795, grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.0280, grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.0247, grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(0.8898, grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.2344, grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(0.9878, grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.0137, grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(0.9580, grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.1656, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 27\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.1137, grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(0.9745, grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.3502, grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(0.8472, grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.1832, grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.0378, grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(0.9004, grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.0497, grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.0424, grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(0.9312, grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(0.9963, grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(0.9798, grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(0.7725, grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.0897, grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.0659, grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(0.9813, grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.1798, grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.2409, grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.0062, grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.0669, grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.1544, grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(0.8517, grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.0319, grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(0.8617, grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(0.8860, grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.1074, grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.3342, grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(0.9998, grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.0000, grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(1.0319, grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(0.7957, grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(0.9346, grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.1237, grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(1.1601, grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.0246, grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(0.9861, grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.2343, grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(0.9742, grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.0764, grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.3551, grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.1916, grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(0.8851, grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.0549, grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(0.9715, grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.0988, grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.1152, grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.0247, grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.0092, grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(0.9863, grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.0547, grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.0327, grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(0.9611, grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(0.8181, grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.0108, grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.0337, grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.0659, grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.4407, grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.0848, grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.0760, grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.2256, grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(0.8900, grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(0.9739, grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(0.9234, grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.0295, grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.1590, grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(0.8027, grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.1496, grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.0817, grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.1348, grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.0109, grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.1270, grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.2323, grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.2532, grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.0985, grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(0.9301, grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(0.9380, grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(0.9553, grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(0.9806, grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.1662, grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(0.8658, grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.1367, grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.1176, grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(0.8961, grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(0.9062, grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.0740, grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(0.9419, grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(0.8353, grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.0675, grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.1228, grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.0723, grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(0.9962, grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.1703, grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.0871, grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.0274, grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.1945, grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(0.9656, grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(0.8319, grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(0.9407, grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.2047, grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.0420, grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.0029, grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(0.8758, grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.1156, grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(0.9929, grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.0233, grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.2111, grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(0.9324, grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(0.9855, grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.0718, grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(0.8609, grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.0725, grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.1810, grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.0780, grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.0987, grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.1371, grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.1516, grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.0291, grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(0.7667, grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(0.8667, grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(0.9816, grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(0.9588, grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.0608, grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(0.9499, grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.4039, grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.0851, grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.1077, grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.0665, grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.0443, grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.0199, grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(0.9080, grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.0085, grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(0.9139, grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(0.9438, grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.0008, grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(0.8828, grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(0.9018, grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(0.9749, grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(0.9868, grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(0.8189, grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(0.9817, grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.1126, grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.2723, grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(0.8528, grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.1130, grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(0.7447, grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(0.8644, grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.0389, grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(0.9599, grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(0.6623, grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(0.9639, grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(0.8806, grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.0681, grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.0458, grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.1436, grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(0.9910, grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(0.9833, grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.0017, grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.1975, grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(0.8805, grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.0695, grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(0.8966, grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(0.9996, grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(0.9216, grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.0612, grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.0012, grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.1903, grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.1357, grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(0.8846, grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(0.7701, grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(0.8965, grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(0.9422, grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(0.8284, grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.0597, grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.2040, grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(0.7588, grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.0610, grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.3976, grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.0171, grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.0852, grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(0.9726, grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(0.9507, grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.4024, grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(0.9975, grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(0.8516, grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.0614, grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.0671, grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(0.8843, grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.2668, grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(0.8875, grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.3719, grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.2058, grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(0.9020, grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(0.9430, grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.0641, grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.0834, grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.1299, grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(0.9072, grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(0.9161, grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(0.9017, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 28\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.0947, grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(0.8918, grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.0480, grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.3094, grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(0.8489, grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(0.8623, grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.2021, grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(0.9112, grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.0425, grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.1346, grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(0.9672, grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(0.8723, grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(0.8401, grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.1887, grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.0320, grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.2341, grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.2775, grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(0.8957, grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.0728, grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.0071, grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.2843, grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.1525, grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(0.9975, grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.0528, grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(0.8313, grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(0.8808, grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(0.8172, grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(0.9087, grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.1278, grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(1.1764, grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.1986, grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(0.8709, grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(0.9092, grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(0.8644, grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(0.8767, grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(0.9843, grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.0853, grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.1668, grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(0.9997, grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(0.9376, grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.2141, grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.3422, grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(0.9372, grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.0504, grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.1437, grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.0849, grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(0.8908, grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.2085, grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.0524, grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(0.9814, grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.1786, grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(0.8979, grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(0.9756, grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.1053, grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(0.8856, grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(0.8829, grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(0.9034, grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.2132, grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.0869, grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.1441, grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.0103, grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(0.9109, grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.1143, grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.1720, grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.0943, grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(0.9524, grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(0.8108, grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(0.9846, grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.2120, grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(0.8417, grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(0.9840, grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(0.8074, grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.0932, grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(0.8426, grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.0449, grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(0.8889, grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(0.8772, grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.1618, grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(0.8048, grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(0.8298, grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(0.8138, grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.1295, grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(0.9078, grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.3850, grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.0986, grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.1044, grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(0.7923, grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(0.8505, grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(0.8852, grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.0803, grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(0.8978, grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(0.9903, grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.2021, grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(0.9497, grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.0856, grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.1213, grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.2298, grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.0874, grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.2299, grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.1170, grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.1731, grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.1257, grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(0.8593, grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.0018, grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(0.8652, grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.1240, grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.0649, grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.0633, grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.1572, grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(0.8510, grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.1075, grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(0.8068, grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(0.9558, grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.0366, grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.0768, grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.0194, grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(0.9792, grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.2029, grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(0.9570, grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.2176, grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.0659, grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.2946, grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.0356, grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.1436, grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(0.9244, grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.1840, grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(0.9510, grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.0569, grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(0.8327, grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(0.8764, grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(0.9577, grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(0.9685, grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.1428, grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.0263, grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.2486, grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(0.8839, grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(1.0400, grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.0618, grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.0800, grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(0.9609, grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(0.8898, grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(0.7871, grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(0.7734, grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(0.9093, grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(0.9276, grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(1.1738, grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(0.8765, grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(0.9542, grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(0.8858, grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.0460, grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(0.9760, grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.1232, grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(0.9426, grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.0132, grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.2157, grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.0402, grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.0463, grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.1994, grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(0.9681, grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(0.9793, grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(0.8804, grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(0.8472, grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.0062, grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.0136, grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(0.8194, grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(0.9102, grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(0.8375, grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.2106, grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.0923, grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(0.6467, grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(0.9195, grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(0.8725, grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.0587, grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.3231, grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.2368, grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.2108, grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(0.8223, grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.1774, grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(0.8668, grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.0852, grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(0.9993, grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(0.9170, grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(0.8294, grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.2077, grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.0070, grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(0.9794, grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(0.9965, grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.1052, grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(0.9460, grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(0.9251, grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.0541, grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.0712, grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.0242, grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.0821, grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(0.9565, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 29\n",
            "================\n",
            "Batch No 0,\tloss is tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.1715, grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(0.8916, grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.1250, grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.2447, grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.0969, grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.1603, grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.2458, grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.0535, grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.3414, grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.0632, grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(0.8908, grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(0.8517, grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(0.9883, grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(0.8221, grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(0.8802, grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(0.6722, grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(0.9932, grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(0.8819, grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.3237, grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.0421, grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(0.8978, grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.0179, grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(0.8152, grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.0202, grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.0466, grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(0.8945, grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(0.8406, grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.1778, grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(0.9628, grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.0287, grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(0.9371, grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.0839, grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(0.9417, grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.2342, grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(0.6542, grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(0.9963, grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.0571, grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.2240, grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(0.9277, grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(0.9516, grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(0.9151, grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.3986, grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(0.9303, grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(0.9458, grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.0673, grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.0885, grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.0489, grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.2420, grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(0.9651, grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.0327, grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.0748, grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.1779, grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(0.8372, grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.1138, grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.0770, grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.0065, grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(0.9060, grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(0.8691, grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(0.9828, grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.0742, grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(0.9639, grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.0460, grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(0.8568, grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(0.8152, grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.3513, grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(0.7667, grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.2703, grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(0.8467, grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(0.8760, grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.0734, grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(0.8561, grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(0.8205, grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.2619, grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.1288, grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(0.9088, grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.1422, grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.2371, grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.1663, grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(0.9822, grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(0.7047, grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(0.7426, grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(0.9492, grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.0433, grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.1543, grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.0688, grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.1322, grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(0.9976, grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.1217, grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.1290, grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.0315, grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(0.8504, grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.0856, grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(0.8551, grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.0232, grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.1106, grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.1219, grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(0.9748, grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(0.7670, grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.0333, grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.1740, grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.0024, grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.0963, grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(0.8657, grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(0.9494, grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(0.9092, grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.2113, grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(0.9722, grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.1814, grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(0.9508, grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.0204, grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(0.8303, grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.0674, grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.1179, grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(0.9020, grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(0.6218, grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.2374, grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(0.9807, grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(0.8675, grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.2034, grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(0.8924, grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(0.9988, grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(0.8999, grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.2694, grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(0.8948, grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.0324, grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(0.9910, grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.0235, grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.0981, grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(0.9766, grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(0.7942, grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(0.9328, grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.0360, grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.1048, grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(0.8205, grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(0.7685, grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(1.0131, grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.0479, grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(0.9788, grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(0.8546, grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.2861, grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(0.9830, grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(0.7547, grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(0.9596, grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(0.9010, grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(0.9518, grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(0.8634, grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.0852, grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(0.9911, grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.3703, grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(0.9755, grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.0668, grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.1012, grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.0921, grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(0.8640, grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(0.9823, grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.0266, grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.0061, grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(0.8886, grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(0.9116, grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.2301, grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.0153, grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.1612, grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(0.9983, grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.4261, grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.1409, grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.0144, grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(0.9356, grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.0353, grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(0.8861, grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.0588, grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.1860, grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.0828, grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(0.7933, grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(0.9418, grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.0237, grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.0065, grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(0.8185, grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.1654, grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.0616, grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(0.9227, grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.1899, grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(0.9681, grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.0301, grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(0.8804, grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(0.8590, grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(0.8239, grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(0.9710, grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(0.8751, grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(0.9487, grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.2035, grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(0.9566, grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.2619, grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(0.9327, grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.1639, grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(0.6813, grad_fn=<NllLossBackward0>)\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NN(\n",
              "  (fc1): Linear(in_features=26, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
              "  (fc3): Linear(in_features=32, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_model(dataloader=testLoaderMFCC, cost_func=nn.CrossEntropyLoss(), model=model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDbiKYC4GUmi",
        "outputId": "65577a7f-5809-4e0f-ad1a-12843576408a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:\t\t\t\t tensor(1.0166)\n",
            "F1 Macro-Averaged Score:\t 0.5251342357566521\n",
            "Accuracy:\t\t\t 0.5675872093023255\n",
            "Confusion Matrix:\t [[ 38  48  49 189]\n",
            " [ 11 260   5  21]\n",
            " [ 39  36 172 109]\n",
            " [  9  50  29 311]] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Βήμα 6: Εκπαίδευση Δικτύου με GPU"
      ],
      "metadata": {
        "id": "D8dHvT3aVzKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NN(input_size=26, num_classes=4).to(torch.device('cuda'))\n",
        "\n",
        "train_model(epochs=30, optimizer=SGD(model.parameters(), lr=0.002), dataloader=trainLoaderMFCC, cost_func=nn.CrossEntropyLoss(), model=model, device='cuda')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fxt2yvqFV3sm",
        "outputId": "5b1c1537-2898-48c1-8518-9c6b26a6d1ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Batch No 73,\tloss is tensor(1.3009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.2807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.2501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.3610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.3380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.2800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(1.3033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.3501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.3139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.3399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.2947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.3120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.3586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.2654, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.2521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.3448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.3359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.2979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.2325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.3418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.3399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.3533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.3419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.3156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.3453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.2652, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.3189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.3492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.3039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.3110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.3192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.3464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.3002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.2808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.3399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.2142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.3492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.2864, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.2719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.2605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.3608, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.2374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.2942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.2734, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.3940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.3688, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.3417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.2510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.2902, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.3408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.2747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.3137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.3295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.2622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.3084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.2896, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.2947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.3326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.3718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.3247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.2554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.2637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.2597, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.3198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.3249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.2205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(1.3539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.2625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.2645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.3298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.2693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.3085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.2745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.2698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.2752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(1.2898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.3199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.3315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.2335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.3291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.2606, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.3121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.3172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.2862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.2550, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.2775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.3063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.1884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.3849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.3053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.3250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.2851, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.2612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.3143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.2998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.3019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.3485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.2856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.3026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.2806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.3404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.3130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.2954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.3189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.2794, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.2602, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.3022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.2671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.3340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.3036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.2620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.3029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.3188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.3066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.2940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.2652, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.2342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.2716, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.2694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.2436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.2808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.3349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.2640, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.3320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.2487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.3799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.3304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 6\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.2780, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.2821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.3721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.3141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.2622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.3441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.2324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.3628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.2908, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.2582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.2671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.2918, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.3221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.2750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.2865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.3277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.3193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.3171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.3070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.3070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.3028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.3067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.2878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.2310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.2709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.3089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.3209, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(1.2755, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.2429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(1.3063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.3116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.3317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.2818, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(1.3268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.2619, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.2629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.3442, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.2922, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.3087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.2225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.2312, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.2896, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.3025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(1.2505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.3419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.3372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.2923, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.2819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.3452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.3565, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.2487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.2800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.2136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.2847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.3528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.3321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.3092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.2630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.2182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.4004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.3145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.2984, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.2567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.2719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.3729, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.2550, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.2381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.3362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.3678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.3008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.2840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.2836, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.2568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.3022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.3317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.2326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.2834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.2554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.2458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(1.2961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.2665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.2431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.3286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.3257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.3251, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.2816, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.2971, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.2556, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.2260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.3004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.3003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.2736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.2925, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.3155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.2419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.3763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.2478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.3270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.2878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.2419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.2584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.2901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.2753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.3154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.2947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.3150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.2723, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.2899, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.2804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.2592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.2921, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.2591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.3328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.3214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.3216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.3169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.3143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.2462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.3544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.3324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.3171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.3362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.2706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.2894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.2467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.2662, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.2737, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.2855, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.3385, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.2323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.2322, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.2865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.2336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.3245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.2802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.2288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.2490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.2635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.2285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(1.3281, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.2822, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.2257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.2737, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.2331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.3600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.2322, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.3303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.2836, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(1.3265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.1847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.2502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.2695, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.3033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.2502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.3010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.2831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.2536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.2952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.3391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.2705, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.2774, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.2417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.2894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.2509, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.3335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.2311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.2911, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.1943, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.2544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.3445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.2167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.3436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.2718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.1740, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.3942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.3418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.2332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.3155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.2854, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.3000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.3122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.2744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.3212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.3223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.2893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.2358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.3287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.4035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.2418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.3190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.2784, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.2852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.2710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.3077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.2627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.2393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.2688, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.3141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.2784, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.2898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 7\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.2776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.2436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.3103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.2326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.2495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.2880, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.2200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.3098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.2371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.2255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.3075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.2490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.2087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.0568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.3115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.3625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.2638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.2787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.2387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.3320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.2988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.2263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.2438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.3449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.2946, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.2404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.4265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(1.3084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.2810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(1.2635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.3431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.2468, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.2457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(1.2552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.2562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.3534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.2175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.2683, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.2314, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.2245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.3512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.2842, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.3166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(1.1904, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.3636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.2358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.2990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.1988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.2870, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.2981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.2301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.2551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.1648, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.3689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.3139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.2669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.2181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.3407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.3150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.2780, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.2845, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.2820, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.3165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.3159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.3331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.2047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.2629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.2226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.2647, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.2835, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.2604, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.3017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.2613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.2014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.3048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.1915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.2451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.2401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.3265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(1.3091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.2824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.2443, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.2387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.3915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.2508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.2738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.3198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.2758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.2411, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.3534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.2559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.2818, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.2955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.3217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.2669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.3127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.2581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.3073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.2562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.2835, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.3419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.2418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.2408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.3374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.3207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.2320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.1952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.2331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.2884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.2474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.3088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.3746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.2346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.3368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.2694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.2324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.2702, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.2844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.2801, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.3436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.2467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.2380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.2898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.2678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.3440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.2368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.2292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.2655, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.3029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.2169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.2289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.1934, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.3267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.2462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.3427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.2350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.3368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.2312, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.2850, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(1.2339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.3034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.3110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.2317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.2550, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.2386, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.3121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.2332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.2784, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(1.2907, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.2954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.3145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.2261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.2341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.2931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.2886, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.2515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.2874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.2765, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.2605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.2412, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.1988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.2771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.2531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.2443, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.2082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.2858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.1899, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.2882, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.2557, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.2457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.2624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.2959, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.2021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.2340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.3216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.3015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.3168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.3041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.2559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.3069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.2082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.2361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.3382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.2609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.3071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.2437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.2115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.2884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.2406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.1420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.1276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.3620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.2871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.3336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.2459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.1878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.2998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.2724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.2947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.2670, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 8\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.3340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.2382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.2346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.2719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.2823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.2345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.3020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.3163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.2572, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.2467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.2696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.2602, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.2125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.3598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.2515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.2801, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.1786, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.3013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.2227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.2817, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.2552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.2039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.2270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.2341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.2530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.2796, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.3222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(1.2177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.2854, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(1.2198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.2671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.2723, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.2994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(1.2611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.2947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.2673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.1822, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.2184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.2256, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.2249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.2775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.2916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.2667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(1.2673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.2087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.2543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.2690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.2101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.3188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.3075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.3715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.2374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.3000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.2600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.2159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.1645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.2855, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.2481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.1866, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.2391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.3252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.3280, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.2608, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.2105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.2254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.2296, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.2579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.1618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.2120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.3344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.1833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.1963, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.2714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.3076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.2336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.2715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.2536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.2087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.2986, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(1.2776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.2386, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.1857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.1808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.2696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.1664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.1625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.2686, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.3217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.2027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.2223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.2547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.2318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.2359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.2407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.2470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.3182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.2609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.2517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.2506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.2467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.1850, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.2591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.2998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.1784, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.3460, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.1427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.2646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.1542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.2510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.2220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.1963, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.2484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.2337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.3823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.2481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.2554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.1832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.2166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.2938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.2275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.1126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.1956, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.2580, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.1484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.2900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.2397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.1993, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.1753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.3611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.3294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.1996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.2650, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.2467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.2521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.2263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.2415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.2359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.1698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.2745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(1.1924, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.2491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.3467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.2481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.2160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.2555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.2544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.2411, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.2665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(1.2271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.2861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.2196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.2015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.2848, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.2324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.2803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.2592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.3377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.2245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.2372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.2941, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.1725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.3659, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.2333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.2947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.2451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.1927, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.2349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.2594, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.1821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.1774, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.3120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.2862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.2418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.2588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.2135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.2031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.3740, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.2819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.2343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.2132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.2255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.2614, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.2292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.2473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.2312, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.1888, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.2790, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.2367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.2160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.1884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.1944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.2801, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.1956, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.2964, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.1832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.2507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.2266, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.3462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.3588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.2109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 9\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.2165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.2954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.2931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.2483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.1572, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.2174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.2904, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.2078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.2324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.0994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.2188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.3066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.2200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.1945, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.2714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.2348, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.1987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.2159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.1879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.1427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.1608, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.0729, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.2878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.2425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.1874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.2004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.3025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(1.1999, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.1684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(1.1092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.3203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.3008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.2575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(1.2094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.2977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.1693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.2786, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.2194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.2918, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.2005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.2364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.2464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.0906, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(1.2236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.2749, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.1948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.3628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.2888, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.2001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.2612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.2137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.1445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.2723, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.2587, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.2204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.1776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.2624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.2032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.1677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.2204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.1869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.2545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.2771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.1694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.2330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.2679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.2191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.2741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.2064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.2485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.2546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.1510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.2211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.2529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.1934, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.2511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.1553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.2237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.2509, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(1.2992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.2379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.1608, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.1609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.2113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.2588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.3191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.1298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.3003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.0453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.2531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.3325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.2564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.1852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.1432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.1951, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.3795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.2966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.2725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.2425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.2492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.2391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.3576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.3077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.1506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.2517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.2753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.2777, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.2206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.1781, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.2458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.2220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.2449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.1984, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.2551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.2610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.2421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.3073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.2514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.1937, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.2725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.1913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.2356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.2919, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.2732, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.2069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.1351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.1857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.3452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.2930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.1779, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.1568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.1744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.2852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.2313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.1990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.2094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.1934, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.2504, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.1466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(1.2368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.1759, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.0963, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.1843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.3381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.2594, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.1871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.1822, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.2644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(1.2886, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.2127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.3043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.2567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.2919, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.2437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.2161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.2825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.2099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.1787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.1995, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.2295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.2357, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.2276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.2763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.2490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.1443, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.0107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.3440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.1533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.1478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.2719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.2684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.1935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.2290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.2077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.2314, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.2538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.1774, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.2341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.2866, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.2753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.2644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.2117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.2623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.2380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.2069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.2399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.2940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.2774, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.2157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.1933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.2233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.1464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.1708, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.2443, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.0895, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.3614, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.2169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.2798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.2953, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.2928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 10\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.1881, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.2309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.2507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.2043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.3230, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.2186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.2248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.2800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.1851, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.1341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.2167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.2167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.3396, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.2156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.2401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.2029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.1875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.1728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.1626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.2767, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.1485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.2219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.2597, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.2548, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.0823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.2791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.2528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(1.1474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.2613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(1.2152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.2807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.1124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.2503, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(1.1516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.2170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.1982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.2347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.1900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.2149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.1782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.2276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.1626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.1183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(1.2176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.2143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.1479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.2688, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.1311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.2572, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.2418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.1961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.1804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.2882, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.2082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.3745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.0190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.2516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.1756, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.0949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.2514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.2505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.1951, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.1465, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.2731, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.2804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.2382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.2520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.2569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.1332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.2367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.2697, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.2215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.2101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.1197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.1905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.0691, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.2247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.2321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.1016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(1.2421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.2407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.2115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.1192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.2390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.1551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.2513, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.2293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.2106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.1552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.2430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.1956, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.1715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.0543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.1027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.2519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.1672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.1628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.2620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.1150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.2021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.1651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.0663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.2391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.3895, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.1038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.4216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.1767, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.1968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.1923, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.3060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.3209, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.2597, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.1184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.1893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.2157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.1757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.1830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.1214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.1428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.2643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.1972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.1566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.1521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.1574, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.1078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.2850, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.2207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.2225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.2861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.1240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.2039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.2501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.1625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.2057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.2562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.1511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.3098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.3760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.2572, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(1.2339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.2486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.2164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.1455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.2690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.1212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.1774, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.2353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.1773, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(1.2600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.1138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.0178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.0057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.1150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.2101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.2201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.1917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.2885, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.2575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.1483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.1741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.2617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.0963, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.2183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.3101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.3313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.1211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.2277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.2568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.1634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.1724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.2167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.2433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.2274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.1810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.2840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.2602, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.1975, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.1680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.2359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.1974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.2969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.1820, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.2328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.2278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.2040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.1579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.2128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.1434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.1682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.0562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.2124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.1341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.2108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.0758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.2173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.2414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.2040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.1641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.2697, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.2893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 11\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.2246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.2239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.2190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.1376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.2401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.1284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.2788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.2305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.0751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.2374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.1185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.1683, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.2805, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.2344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.1231, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.1655, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.1741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.2978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.2159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.1024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.1563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.1725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.1860, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.0972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.1596, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.1751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.1723, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(1.0954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.2282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(1.1370, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.2357, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.1166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.2238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(1.1301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.1662, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.2534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.1400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.3048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.3119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.1540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.1700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.1856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.1266, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(1.2368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.1561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.0585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.2082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.2523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.1047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.2972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.1008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.1360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.1571, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.2084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.2484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.2400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.2569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.1958, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.0454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.3227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.2567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.3499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.2583, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.1994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.1489, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(0.9736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.2715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.0940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.2592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.2621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.2268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.2663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.1954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.2358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.2810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.2010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.2041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.3019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.3232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(1.2133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.1014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.1663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.1674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.1456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.1681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.1907, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.2271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.1884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.1583, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.1098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.1197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.0720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.1571, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.1724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.1129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.2303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.1089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.2148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.2503, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.1722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.1302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.2098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.1823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.2370, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.0664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.1653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.0823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.2205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.1175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.1734, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.0143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.3424, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.2307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.1193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.1873, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.1557, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.1692, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.0992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.1264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.1968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.2552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.2009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.1214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.1940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.2138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.1689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.2628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.2514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.2007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.0563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.1144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.1616, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.1533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.2210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.1087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.1496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.2204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.1626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.2413, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(1.1931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.1417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.2763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.1973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.0957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.2437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.2199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.0640, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.0617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(1.2204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.1661, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.1519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.1927, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.1945, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.2153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.0879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.2014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.0948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.2618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.1122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.2225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.1302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.1240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.2657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.0880, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.2820, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.1885, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.2673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.2048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.2076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.4225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.2578, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.2789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.1514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.2097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.1676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.1239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.0115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.3646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.0941, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.0767, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.2852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.1128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.1481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.1684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.1924, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.1970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.1405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.2700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.2162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.2256, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.1446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.1677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.1475, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.1231, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.2487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.0537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.0947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.2351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.1514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.1516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 12\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.2895, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.1226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.1522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.1221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.2592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.2489, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.2714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.2734, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.1104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.0684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.2893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.2978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.1482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.0691, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.1497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.0574, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.1136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.0859, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.2300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.3050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.1235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.1880, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.2419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.1146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.1780, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.0605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.2155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(1.1668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.1215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(1.0658, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.1197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.1350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.1492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(1.1805, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.2002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.1245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.1517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.2067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.1916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.0412, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.1523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.2474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.2863, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(1.0854, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.1079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.3198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.1725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.3604, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.0087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.2172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.1172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.1706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.2651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.2276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.1806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.2607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.1194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.3249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.3372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.0772, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.1126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.1349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.1684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.1776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.1694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.1388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.1697, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.0318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.0551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.0917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.0959, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.1853, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.2007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.1741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.1381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.1207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.2521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.1210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.1498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(1.1059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.2132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.3068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.0472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.2859, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.1750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.1983, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.1998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.0792, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.1518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.1486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.1628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.0330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.2883, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.1141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.0315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.2264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.0317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.2396, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.1612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.0906, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.1755, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.1532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.2011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.1521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.0876, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.0517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.2137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.1684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.2552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.1051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.3517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.2066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.1043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.1037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.2235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.0078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.1431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.2104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.1824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.1293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.1056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.1624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.0991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.1059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.1383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.1380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.1829, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.0482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.1662, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.1666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.1535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.1681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.2069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.3335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.0628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.2693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(0.9067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.0307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.2976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(1.1892, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.1561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.0625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.1211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.1908, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.0532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.1137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.1460, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.2027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(1.1021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.1501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.2259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.1531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.0861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.0522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.1989, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.1481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.0593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.0784, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.0377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.0996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.1118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.1809, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.1942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.2068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.1565, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.1289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.3057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.0382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.2920, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.0598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.1965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.2019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.1165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(0.9952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.1871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.1659, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.2056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.0609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.0385, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.0389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.2065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.1683, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.0679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.1991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.2544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.1157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.2079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.1158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.1101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.0614, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.1274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.1469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.1903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.2268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.1356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.2905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.1847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.1974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.2705, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 13\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.1014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.1100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.1468, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.1392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.3730, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.1183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.1777, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.1433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(0.9233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.2010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.1362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.2412, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.1073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.2634, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.1254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.0397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.1694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.0718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.0610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.2396, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.2289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.0584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(0.9613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.2631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.2479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.1845, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.2356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(1.1391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.1567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(1.1673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.1689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.1776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.1880, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(1.0848, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.1795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.1169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.0269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.1568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.0964, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.2505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.0519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.1193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.0782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(1.0563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.1582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.3524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.1912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.1410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.1221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.0525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.1885, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.0628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.2429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.0479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.1460, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.2117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.1462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.0555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.3761, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.0432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.1354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.3434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.2505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.2484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.1371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.1659, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.2449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.1425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.2795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.0577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.1591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.2295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.2204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.1714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.1258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.0317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.0800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.1615, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(1.0819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.2575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.1639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.1597, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.1216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.2739, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.1688, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.3395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.1796, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.0860, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.1715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.1941, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.1077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.0644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.1645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.2636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.1111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.3865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(0.9383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.2549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.0365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.1079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.0443, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.2877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.1226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.1733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.1495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(0.9827, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(0.9710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.1154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.1983, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.2616, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.1676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.0432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.2505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.2047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.0351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.3136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.1506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.1841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.3343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.0713, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.0744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.1269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.1613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.2631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.0717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.0906, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.1515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.0343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.0377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.3035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.1198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.0504, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.1014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.1568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.1815, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.1044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.1454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(1.0273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.1659, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.2261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.0253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.1878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(0.9980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.1957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(0.9933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.1675, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(1.2367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.0206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(0.7238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.0335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.3379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.0842, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.0390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.1697, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(0.9235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.1234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.1344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.1353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.1966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.0324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.0914, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.2571, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.0110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.0341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.0475, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.2241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.2119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.0531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.0218, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.2919, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.1773, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.1693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.0947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.2408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.0738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.1291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.2177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.2942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.1698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.2789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.0227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.0847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.1737, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(0.9325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.0286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.1549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.0834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.0106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.0891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.1286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.0330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.0481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.1502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.2478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.1652, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.0787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 14\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.0299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.1440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.0857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.0981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.2274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.3464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.1841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.1949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.2037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.1283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.0448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.1987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.2002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.1267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.1853, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.1594, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.0805, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.2380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.0811, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.1663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.1072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.2351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(0.9633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.1276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.2046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.0150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.0673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(1.1065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.0858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(1.0528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.0663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.1022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.1193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(1.1398, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.2169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.1074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.1795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.1156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.1067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.0184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.1573, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.2259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.1056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(1.2011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.0459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.1269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.3494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.1503, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(0.8838, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.0767, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.3451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(0.9889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.2700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.1031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.1837, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.0522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.1835, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.0780, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.1300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.2272, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.1488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.0774, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.1142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.3075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.0550, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.1365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.1299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.1313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.0910, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.2027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(0.8988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(0.9425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.1259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.0660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.1281, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.2784, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.1070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(0.9674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(1.0046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.1571, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.3749, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.0983, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.1073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.0570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.1388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.1663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.0182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.2512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.1225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.1051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.2478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.1323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.1153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.0547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.1341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.2497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.1460, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.1904, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.1183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.1436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(0.9887, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.0326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.1973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.1669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.0880, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.1672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.1285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.1522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.0079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.1724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(0.9782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.1071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.1563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.1318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.0568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.0538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.2044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.1243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.0886, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.0958, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.0559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.2332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.3596, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.0545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(0.9865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.1497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.1731, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(0.9652, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.1001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.0481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.3097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(0.9033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.1941, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.2032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.1063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.1874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.1261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(0.9836, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.0977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.2136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.1594, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.1515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.1027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.1458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.2033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.0502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(0.9366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.0832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.0111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.1405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.0807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.1600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.1163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.1016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.0421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.0597, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(0.9852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.1625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.1233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.1611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.1815, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(0.9711, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.0496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.1110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.0164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.1401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.0701, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(0.9665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.2376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.1917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.0902, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.0863, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.1784, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.0815, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.0964, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(0.8804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.0271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(0.8718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.1651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.0285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.2081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.1007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.1587, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.0458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(0.9728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.2499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.1217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.2337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.1486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.0603, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.2408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.1820, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.2006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.2057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(0.8860, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.0722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.0668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.0948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 15\n",
            "================\n",
            "Batch No 0,\tloss is tensor(0.9874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.0630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.2219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(0.8681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.2746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.1084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.0405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.0316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(0.9658, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.0861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.1488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.2178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.2675, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.1510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.2740, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.2102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.2399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.0101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(0.9322, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(0.9509, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.2775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.0871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.1560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.0967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(0.8931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.0559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.1348, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(1.1965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.0948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(1.1328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.2455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.1423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.1364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(1.1269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.1560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.1062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(0.8861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.1764, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.3288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(0.9939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.3090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.0664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.0242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(1.0575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.1567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.0835, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.0268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.1188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.0898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.2102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.1213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(0.8544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.3243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.1861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(0.9579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.1212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.0267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.0917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.0340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.1616, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.1686, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.1737, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.1136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(0.9636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.0205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.1419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.0736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.1053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.1474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(0.8818, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.1043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.0401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.1676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.1775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(0.9736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.1825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.0889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.1450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.0347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(0.9514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(0.9504, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.0737, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.1478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.3661, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.1679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.1106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.1533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.1949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.3179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.2361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.0092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.0365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.1699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(0.9847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.1877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.0389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(0.9638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.0754, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(0.8125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.0999, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.1201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.0185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(0.9042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(0.9952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.1022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.1506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.0717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.1268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.1094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.2631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.0784, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.0491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.1041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.1081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.0956, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.0367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.4593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.0553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.2218, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.1365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(0.9428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.0963, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.0821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.1127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.0077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.0194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.1566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.2472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.1139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.1271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.0573, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.1279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.1166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.1546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.0718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.2213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(0.9868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(0.9676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.1561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(1.1666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.0586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.1985, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.0386, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.1058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.0227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(0.7850, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.1343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.0776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(1.0728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.2759, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.1052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(0.7849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.0745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.0944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.1184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.1700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.0214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(0.9915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.0552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(0.9922, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.0358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.1546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.1230, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(0.9797, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.0617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(0.9876, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.0520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.1861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.0212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.2441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.1778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.2574, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(0.8772, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.2447, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(0.9673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.1889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.2498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.0582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.1048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.0590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.1300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.0191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.0674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.1757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.3200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.1298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.1412, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.0670, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(0.9717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.1585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.1236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.0474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.3736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.0656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.0286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.0304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.2008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(0.9916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.0808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(0.9494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 16\n",
            "================\n",
            "Batch No 0,\tloss is tensor(0.9744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.2472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(0.9609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.0935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(0.9356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(0.9706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.0166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.2030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(0.9398, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(0.9907, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.1304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.0960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.0595, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.1381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.0861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.1382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(0.9914, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.1975, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.1088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.0278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.1913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.3660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.0366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.1248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(0.9762, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.0559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(0.9978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(0.9714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.1607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(0.8822, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.0849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.0342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(0.9912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(1.0381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.1385, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.1841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.1164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(0.9615, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.0828, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.0679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.2659, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.1357, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.0593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(1.1520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.1178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(0.9534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.1775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.1445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(0.9607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.0745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.3078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.0925, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.1291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.2750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.0796, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.1002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.0493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.1457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.2563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.0322, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.0810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.1053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.1875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.1654, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.2003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.1303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.1302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.2121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.0250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(0.9197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.1731, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(0.9869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(0.8047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(0.9579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(0.9201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.3308, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.2540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(0.8579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.0613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(0.9631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(0.9530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(0.9068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.1311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.1806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.2593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(0.9145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(0.9491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.0220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.1068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.0910, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.1403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(0.9133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.0484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.1325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.1843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.0110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(0.9779, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.0859, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.0781, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(0.9717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.0705, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.1296, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.2910, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(0.9965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.0815, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.0623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.2076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.0298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.0722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(0.8519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.1555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(0.8585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(0.8760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.1253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.3812, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.1528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(0.9721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.1698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.1036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.0829, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.0304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.0535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.0730, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.0285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.0806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.0766, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.2083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.1454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.1134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(0.9959, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(0.9394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.0931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.0769, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(0.9997, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.1078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(0.9950, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(0.8227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.1932, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.0326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(1.1163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.1580, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.0945, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.1641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(0.9488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.1569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(0.9095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.3016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.1842, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(0.9734, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.0100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.1662, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.1669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.0864, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.2700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.1165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.2367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.2048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.3896, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(0.9664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.0450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(0.9258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.1461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.3902, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(0.9697, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.1041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(0.9272, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.2279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.0889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.1445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.1852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.1169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.1143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.2109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.0446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.0203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.0922, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.0152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.3208, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.0600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.1104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.2328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.2510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.0242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(0.9104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.0701, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(0.9789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.3131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(0.8872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(0.8550, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.1476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.1488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.1954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.0654, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.1760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.0720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(0.9913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.3109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.1051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.1222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(0.8873, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 17\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.1221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.0407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.1515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.0400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.1888, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.2905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(0.9455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.1695, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.0794, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.0662, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.1819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.0503, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.2430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.1967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(0.9332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.2732, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(0.8840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.0893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.0197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(0.9445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.1595, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.0317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.1371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(0.9974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.1494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(0.9687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(0.9204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.0167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(1.0222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(0.9653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.1393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.0286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(0.8687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.0883, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.1114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.1042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.2157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(0.8489, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.1308, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.0761, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.0763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.1934, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(0.9562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.0718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.1096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.1367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.1450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.0177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.2917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.4439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.1153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.1439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.1546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.0571, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.1027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(0.9631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.0445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.1113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.2240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.1938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.1042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.1021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.0788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(0.9728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(0.9912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(0.9807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(0.8724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.0189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.1097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.1368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(0.9116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.1844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.0495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.1592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.0531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(0.9461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.0367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(1.0883, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(0.9674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.1100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.0177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(0.8917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.0849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.2399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(0.8820, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.0339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(0.8978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(0.8546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.3105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(0.9267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.1518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(0.8608, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.1164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.0488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.2337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.1382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.1018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.1618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.0458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.2105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.2110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(0.9719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.1515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.1273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.1838, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.0848, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(0.8895, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.1617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(0.9370, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(0.9251, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.0331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(0.9092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.0142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.0514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.0803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.1173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.0124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.2405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.2941, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.0750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.0212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(0.9541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.2929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.0432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.0514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.0994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.1489, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(0.9689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.0828, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.0187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(0.8799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.3290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.1335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.0227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.0479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.2221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.0738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(0.8235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.3898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.1337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.0846, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.1434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.0162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.1543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.1719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.0291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(0.9660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.0986, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.1335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(0.9603, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.0885, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.1700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.1164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(0.9998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.1464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(0.9696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(0.8294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.2128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(0.9038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.0967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(0.9493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.3008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(0.9452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.0692, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.0640, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.1584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.0617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.0279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.1437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.2013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(0.9486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.1960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.0274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.1002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.0123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.1967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.1093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(0.9096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.0281, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.0369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.1791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.0979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.0182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.0243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.0038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.0823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.1572, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(0.9841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.0546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.0636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(0.9102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.0125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(0.9526, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.1214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(0.9554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(0.8889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(0.9686, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.0884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 18\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.1793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.2232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(0.9129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.0152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.0667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.0606, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.0745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.0703, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.0543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(0.7893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(0.9586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.1406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(0.9840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(0.9188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(0.9011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(0.8401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(0.9930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(0.9726, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.0277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(0.9343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.0918, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.1104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(0.9791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(0.9663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.0552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.0702, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(0.9821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(0.9820, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(0.9960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.0169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(0.8750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.1660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(0.9933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(0.8626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.3414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.0294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.0400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.0171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.1251, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.0996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.0920, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.0365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(1.0718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.2635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(0.8987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.0497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.1996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.0190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.1263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.0944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.1952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.2833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(0.9190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(0.9267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.0149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.0381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.2268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.0403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.0376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.2183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.0179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.1968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.1719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.2088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.1055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.0812, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.0551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(0.9777, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.1057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.1729, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.2100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.0439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.1513, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.0825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.1069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(0.9806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.1504, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(0.9708, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.0491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.0761, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.1126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(0.9245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.0738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(0.9751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(0.9900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(0.9936, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.1753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(0.8464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.1594, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(0.9363, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(0.9910, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.1981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.2915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(0.8577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.1652, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.1145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.0480, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(0.9912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.0713, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.3521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(1.0421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.3685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(0.9903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(0.9742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.0138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.3395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(0.9775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.2187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.0549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(0.9881, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.0266, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(0.9750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.1538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.1362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(0.9870, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.1469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.0613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(0.9927, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(0.8188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.0285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.2653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.0975, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(0.9496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.0851, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.0557, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.0107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(0.8537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(0.9644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(0.9641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.0226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.0872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(0.8320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(0.9153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.3459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.2028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(0.9944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(0.8626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.2117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.2019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.0310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(0.7889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.0371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.1989, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.1106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.0753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(1.0307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(0.9399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.1211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(0.8385, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.0854, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.0265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.1666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.0852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(0.9602, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.1057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(0.9743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.2165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(0.8432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(0.8092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.3603, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(0.8522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(0.9488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.0055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.0530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.2061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.0412, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.0228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.1807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(0.9301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(0.9908, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(0.9853, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.0715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.1858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(0.9995, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.0196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.0733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.1272, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(0.8652, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.2236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.0083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.1359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.2083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.1583, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.0137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(0.9684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(0.9765, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.0620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.0405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.0965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.1151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.0555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.0533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.2095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.1041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.1434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.1118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 19\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.0081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.1007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.0732, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(0.9738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(0.9788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(0.9243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.3158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(0.9578, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(0.7318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.0344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(0.9947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.0585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(0.7722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(0.8474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.3044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.0669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(0.9650, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(0.9430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(0.9760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(0.9528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(0.9279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(0.9441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.1131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.0149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.0394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.2459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(1.1486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.2971, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(0.9672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(0.8317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.0892, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.0459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(0.7928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.1798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(0.9857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(0.9456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.0101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.1135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(0.9542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(0.9875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.0356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(1.0753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.1434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.1256, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(0.9844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(0.9760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.0941, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.1244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.0354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.3784, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.0857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.0670, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.1790, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.1047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.1188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.0583, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.0573, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.0118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(0.8917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(0.8265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(0.8875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.0803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(0.9317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.0421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.1921, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(0.9971, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(0.9576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.1484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(0.9535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.2613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.4213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(0.8785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(0.9858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(0.8788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(0.9463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.1441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.0263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(1.0225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(0.8632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.0263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.2724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.2252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(0.9341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.2169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.0649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.2580, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(0.8404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.1616, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.1946, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.0455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(0.9891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.1854, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.0523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(0.8479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(0.9174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.0977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(0.9950, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.2489, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(0.9908, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(0.9473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(0.9680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(0.9578, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.1642, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.1996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(0.9159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(0.9198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.0425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.2010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(0.9753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.0358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.1467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.1161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(0.9267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(0.8527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(0.9984, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(0.8724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(0.8573, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.2313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.0660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.0402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(0.9885, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(0.9641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(0.9951, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.1110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(0.9228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.0405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(0.9732, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(0.9533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.0612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(0.9307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.1439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.0504, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.0162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.5020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.0521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(0.9622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(0.8949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(0.9042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(0.7453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.1089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(0.9461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(0.9081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.0418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(0.8890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(0.9147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(1.2488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.1552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(0.9317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.4012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.3078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(0.9827, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(0.9823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.0988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.0079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.0043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.1748, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.0371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(0.9183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(0.6716, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(0.7324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.1757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(0.8519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.1482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.0622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.2056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.0131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.0088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(0.9938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(0.9880, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.0244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(0.9003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.2042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(0.9562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.0898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.0670, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.2119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.0379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(0.8836, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.1885, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.2715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.0155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.1319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.1603, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.1660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.2566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.3228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(0.9776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.0112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.2382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.2967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(0.9694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(0.9375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(0.9857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.1032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(0.9811, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(0.9247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 20\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.2009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.0153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(0.9211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(0.8570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(0.8983, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.2194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(0.8916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(0.9373, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(0.9529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.1576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(0.9821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(0.9356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(0.9870, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.0350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.0236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(0.8633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.0778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.1125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(0.8076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.3496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(0.7562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.1907, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(0.7856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.1794, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(0.9791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(0.9982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(0.9490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(0.9582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.0096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(0.9772, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.1447, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(0.8973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(0.8406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(0.8787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(0.8691, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(0.9057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.2089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.1032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(0.9309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.0418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.0482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(0.9979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.1210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(0.9976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.0445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.1267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(0.9121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(0.9439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.0619, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.1516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(0.9135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.0180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.1671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.1307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(0.9644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.0138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.1648, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.1899, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(0.9169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(0.8705, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(0.9848, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.0141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(0.9869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.1255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(0.9798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(0.8323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.0969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(0.9927, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(0.9959, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.1078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.1372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.0369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(0.9705, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.1561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(0.8815, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.2721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.1100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.3460, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.1885, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(1.0967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(0.9808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.3420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.3080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.0676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(0.9670, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.1215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(0.8938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.1097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(0.8611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.0763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(0.8584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.1085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.0193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.1881, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(0.9722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(0.8438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.0877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(0.9402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(0.9674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.0600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.2868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.1081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(0.9934, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.0524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(0.9016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.0403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(0.9677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.1656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(0.8894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(0.9706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.3593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.0397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(0.8523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.3178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.1248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.0749, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(0.8339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(0.9756, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(1.0087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.1707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.1761, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.0752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.2005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.0166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(0.8112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.0848, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(0.8612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.0527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.0773, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(0.9778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(0.9392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.1656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(0.9286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(0.9169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.1732, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.1917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.1411, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(0.8016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.0725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(1.0460, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(0.7927, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.1664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(0.8448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.0863, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.0128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.0345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.0844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.0496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(1.1932, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.1808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(0.9940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.0578, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.1720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(0.9365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.0315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(0.9820, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(0.8046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(0.8912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(0.9388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.2326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.0061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.0091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.0497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.1211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(0.9689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.0345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.1117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.0081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.1996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.0299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(0.9626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.0111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.2047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.0602, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(0.9350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.0461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.0347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.0519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(0.9374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.0529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.0164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.0546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.2284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.0862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.2839, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.0395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(0.9407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(0.9850, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.1256, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(0.9676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(0.9182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.1364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(0.8799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(0.9968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.0377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(0.9455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(0.9763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(0.7594, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 21\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.0077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.0800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(0.9820, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.1236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(0.8988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.1540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.0176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.2865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.0971, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(0.9577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(0.7966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.1763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(0.8125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.1289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(0.9285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.0560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(0.9696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.0618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.1170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.0485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(0.8995, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.0456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.0472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.2973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.0306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.0533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(1.0150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.0074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(0.8930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.0908, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.2380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(1.0395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.1519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.1299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(0.9803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(0.9228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.0133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.0429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(0.9459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.0443, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.0431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(0.8933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.0652, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(0.8218, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.1130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(0.9894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.0834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(0.9290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(0.8828, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.1860, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(0.9527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(0.8239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.0808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.0856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.1868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(0.9926, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.2759, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(0.9404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.1293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.2301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.1035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.0726, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(0.8496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(0.9096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(0.9787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(0.7636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(0.9877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(0.8944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(0.9493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(0.8295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.0743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(0.9050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(0.9339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(0.8019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.1049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.0455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(0.8087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(1.0511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(0.8814, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.0988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(0.9332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(0.9269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(0.9422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(0.9413, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(0.8564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.2464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.2694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.5084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.1372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(0.9545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.1248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.1168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.0502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(0.9615, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.0491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.1423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.0936, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.1124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.1548, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(0.8830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(0.7527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.0921, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.0097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(0.9230, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(0.8627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.0703, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(0.9774, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.0258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.0460, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(0.9843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(0.8715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(0.8379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(0.8555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.3561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.0705, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(0.7749, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(0.9559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.2225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(0.9056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.0869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.1176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.0100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.0937, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(0.8384, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(0.9852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(0.9254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.1750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.0585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.0807, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.1158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.1730, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.2517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.2069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(0.9243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(0.9027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.2746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(0.8611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.2167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.0708, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.1556, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(0.9345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.0311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(0.9953, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(0.7881, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(0.8867, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(1.0210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.1707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.0649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.0320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.0268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(0.9282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.0145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(0.7361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(0.9301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(0.8187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(0.9971, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.0161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(0.9265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(0.9012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.1116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.3002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.0329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(0.9810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(0.9259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.3305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.0242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.3109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(0.9533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(0.9568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.0167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.0488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(0.9329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.1203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(0.9106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(0.9907, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.0143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.0418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.1542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.0429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(0.8374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.0055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(0.8687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.0757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.0667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.0098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.2151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.2521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(0.8825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.0641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.0723, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.1165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(0.7750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(0.8810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.0517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(0.9364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 22\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.1842, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(0.9484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.0991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.1319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.1410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(0.9544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.0534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(0.8099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(0.8654, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(0.8688, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.2892, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.2519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.0072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.2184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.0142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(0.9965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(0.9107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(0.9646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(0.7268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(0.8543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(0.9847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.1733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.1106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(0.9279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.0835, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(0.9467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(0.7911, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(0.9856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.1658, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(1.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.1318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.2621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.0158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(0.9593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.2271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(0.8890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(0.9055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.0477, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.0311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.1281, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.0393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(0.8561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(0.8890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(1.1843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(0.9989, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.0434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(0.9946, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(0.8355, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.1367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(0.9548, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(0.9344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.1244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(0.7676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(0.7971, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.1689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(0.8608, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.0545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(0.9911, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.0200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.4566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.1622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.0961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.0224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(0.8690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(0.9375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.0098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.1874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(0.9463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.0432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(0.8898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(0.8144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.0946, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.2243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(0.9501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(0.8955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.0085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(0.9632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.0424, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(0.8783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.3698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(0.8774, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(0.9549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.1081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.0552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.0243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(0.9388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.1888, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.0177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.0177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.1461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(0.8678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.0686, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(0.8725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(0.7452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.1224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(0.6739, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.2450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.1336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(0.9212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(0.9526, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(0.9467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.1459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.1284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(0.9685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(0.8630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(0.9619, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(0.8402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(0.9020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.0601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(0.9605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(0.9515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.1755, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.0532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(0.8040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(0.9455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.2128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(0.9278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.1909, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.0637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.1901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.0372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(0.9198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.2875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.0667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.2061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.0468, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.1506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.1825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(0.8338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(0.8349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(0.6933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.1176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(0.9711, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(0.9431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(0.9141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.1366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.0296, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(0.9759, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.1084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(0.9164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(0.9129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.1817, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.0438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(0.9342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.0308, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(0.9330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(0.9489, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.0845, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.1906, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(0.9980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(0.8645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.0520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.1459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(0.6843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(0.9075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(1.0160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.1522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(0.8690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(0.8341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(0.9021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(0.9973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.0513, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.2514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.1915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.0218, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.0209, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(0.7135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(0.9768, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(0.9834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(0.9515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.1836, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(0.8771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(0.8811, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(0.8588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(0.9392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(0.9172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.2576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(0.9949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(0.8644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.0309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(0.8517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(0.9151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.2026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.0709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(0.9392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(0.9242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.1616, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(0.9178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(0.9046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(0.9600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(0.8056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(0.7827, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.0938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(0.9024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.2390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(0.8730, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.2686, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 23\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.1796, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(0.7968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(0.7426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(0.8661, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.1518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(0.9088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(0.8632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.0591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(0.7979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(0.7271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.2444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(0.9059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.0327, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(0.8563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(0.9916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.1866, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.0392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(0.8750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.1523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(0.7190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(0.9621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(0.9770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.1920, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(0.8037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(0.8270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(0.8815, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(0.9843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(0.9582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.1789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(0.7799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.0311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.1023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.1759, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(1.2359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.2642, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.0563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.1766, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(0.8737, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(0.8642, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.0819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.0460, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.0904, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.1835, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(0.9299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.3691, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(0.9095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(0.8852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.0938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(0.8981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.2491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.1522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.0396, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(0.9617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(0.9370, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(0.9298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.0067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(0.8630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.0266, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(0.8490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(0.9575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.0763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(0.7947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.0466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.1342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.0860, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.2803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(0.8784, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.1703, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.2236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(0.8147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(0.9282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.1284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(0.9494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(0.9802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.1564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.1355, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(0.7995, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(0.8423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(0.9711, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(0.8493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.3767, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.1474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.0798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(0.9134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.0417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(0.8635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(0.9796, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(0.6318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(0.9970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.0191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.3260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.2097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(0.9896, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(0.9427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(0.7450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.4129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.1120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(0.8645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(0.8796, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.1045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(0.9338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(0.9011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.0763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.1332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.0534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(0.7590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(0.8740, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(0.9248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.0291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.0256, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.0309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(0.9072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(0.9268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(0.9286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.0722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(0.9283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(0.9013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(0.8736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.0257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.0161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(0.9982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.0606, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.0310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.0438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.0551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(0.9844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.2646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.0339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.2446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.1569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(0.9962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.4040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(0.8782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.1417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(0.9429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.3089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.0091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(0.9620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(0.9787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(0.8774, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.0347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(0.9102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(0.8185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.0947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(0.9933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.0735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.1318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(0.8741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.1119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(0.9279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(0.9131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(0.8714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(0.8158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(1.0224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.0692, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(0.8850, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(0.9026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(0.9505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(0.8921, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(0.8597, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.1841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(0.8914, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(0.9804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.0104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.0617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.1778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(0.8515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(0.9451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(0.7966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.1922, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(0.9063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(0.9520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(0.9079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.0947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(0.8457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(0.9619, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.1026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.0103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(0.9219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(0.9238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(0.9783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(0.8651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.1531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(0.8908, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(0.8493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.0094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(0.9533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(0.7533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.2615, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(0.7342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(0.8429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(0.8165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(0.8747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.0509, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.0339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.0161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(1.0075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.1467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.1425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 24\n",
            "================\n",
            "Batch No 0,\tloss is tensor(1.1200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(0.8628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.3128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.2053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(0.9901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.0567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(0.9913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.1552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(0.9425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(0.8726, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(0.9219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(0.8777, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.0144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.0299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(1.1639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.1676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(0.7487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.0464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.0083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(0.7981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(0.8930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(0.9735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.0714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.0812, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.0204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(0.8760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(0.9547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(1.1849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(0.9550, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(0.9834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(0.9843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(0.9282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(0.9019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(1.1563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(0.8945, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.0051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(0.9620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(0.9432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(0.8668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.2809, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(0.8371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.2043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(0.8905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(0.9187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(0.7310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.1472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(0.8694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.1628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(0.8149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(0.6725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(0.8426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(0.7528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(0.9688, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.0922, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(0.9722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.0564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.0409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(0.8123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.2407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.2133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.0671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.3296, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.0445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(0.9275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(1.1106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(0.8253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(1.4228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(0.8336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.2124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(1.2031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.0720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(0.9430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(0.9496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.1459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(0.8025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(0.8992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(0.9498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(0.8170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(0.9932, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.1031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.0611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(0.8105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(0.8149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(0.8352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(0.7539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(0.6586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.1775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(0.9677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.1136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.1752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(0.6401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(0.8166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.1763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.0607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.1052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(0.9278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.0629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(0.8240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.1954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.3999, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.1313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(0.9133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(0.8329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(0.9702, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.2171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(0.8478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.0614, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.2307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(0.9140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.0599, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(0.8757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.1427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(0.9322, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(0.9754, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.0121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(0.9451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(0.8197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(0.7276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(0.8600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(0.7324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.0212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(0.8456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.0198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.0238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.1055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.0651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(0.6391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.1824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.0712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(0.9102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(0.9871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(0.9299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.0207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.3250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.0935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(0.9882, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.2687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(0.9236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(0.9361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(0.9115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(0.7628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.0946, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(0.9192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(0.9023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(0.8127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.0523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(0.8811, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.2123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.1703, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(0.8430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(0.9233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(0.9972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(0.7517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.0274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(0.9993, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(0.8129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.1271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.0840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.4374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(0.8347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(0.9933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.0056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.0088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.0304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.0071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(0.8382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(0.8884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(0.9483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(0.7836, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.0881, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(0.9846, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.3361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(0.8830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(0.8898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(0.8245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.2144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(0.9515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(0.7929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.0954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(0.8825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(0.8896, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.1151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.1527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.0860, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.2724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.0676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.0130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(0.6766, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(1.0628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.2930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.0545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(0.9377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(0.9109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(0.7882, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(0.8727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(0.9875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.0529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 25\n",
            "================\n",
            "Batch No 0,\tloss is tensor(0.9612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.2172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.1419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(0.9826, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(0.7981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(0.8928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.1466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(0.9325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(0.9746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(0.9285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(0.9992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(0.9214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(0.8551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(0.9540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(0.8743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.1178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(0.8731, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(0.7636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.1117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(1.0656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(1.1296, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.1755, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(0.9122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(0.9549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.0161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(0.8824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.0099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(0.9937, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(1.2426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(1.0566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(0.8354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.1257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(0.9527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(0.9934, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(1.0585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(0.8444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(0.8639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.1787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(0.9324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(1.1456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.1823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(0.7831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(0.9934, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(0.7254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(0.9631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(1.0054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(0.8704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.0580, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.0373, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(0.9014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.1138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.1142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.1035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(0.7799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(0.8244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(0.8959, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.1394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(0.8143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.0189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(0.7489, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(0.8084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.0953, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.6502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(1.1660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(0.8706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(0.9828, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.0234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(0.9550, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.0624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(0.9450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(0.9015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.1156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(0.9475, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(0.8938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.1068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(0.7748, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(0.6816, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.0990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.1334, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(0.9230, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.2133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(1.2611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(0.7552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(0.9376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.0886, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(0.9574, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.0605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(0.9024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.2608, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.0596, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(0.9766, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.2382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(0.7509, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(0.8697, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(0.9018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.2882, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(0.7680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(0.9298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(0.8854, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(1.2128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(0.8532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(0.9231, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(0.8898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(0.7729, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(0.8238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.3178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.1412, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.0454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(0.9122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(0.8851, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(0.9437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(0.8193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.3458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(0.9752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(1.0977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(0.9969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.3553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(0.8593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(0.9280, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.0890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(0.8977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(0.8141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(1.1444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.0429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(0.8199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(0.8090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.3889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(0.9387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(0.8714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(0.8445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(0.7448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(1.1399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(0.9864, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.1315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(0.9149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(0.8457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(0.7079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.0202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(0.7723, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(0.8012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(0.9794, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(1.0818, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(1.0229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(0.7809, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(0.7365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(0.7590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.0767, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(0.9476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.2617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.1532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.0416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.2128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(0.9926, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(0.7407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(0.7281, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(0.8080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(0.9326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(0.9548, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(0.8423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.0578, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.1145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(1.1117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.2185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(0.8418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(0.9457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(0.8824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(0.7166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(0.9852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(0.7844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.1677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(0.8262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.1175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.2651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.0691, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.0113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.1255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(0.8177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(0.7927, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(0.9233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.0051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(1.2055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(0.9859, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(1.0467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.0865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.0504, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.0434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.1710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.0954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(0.7293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(0.8091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(0.9064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.0400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(0.8421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(0.7880, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(0.8834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.0522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(0.9667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(0.9110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(0.8266, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 26\n",
            "================\n",
            "Batch No 0,\tloss is tensor(0.9750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.0732, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(0.7842, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(0.9164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(0.8882, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(1.2087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(0.9483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(0.8621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(0.8791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(0.7367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(1.0462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.1754, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(1.0565, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.0205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(0.9098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(1.0741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(1.0741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.0816, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(0.6684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(0.7170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(0.9787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(0.9475, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(0.7366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.4559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(0.9480, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(0.8242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.2785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(0.9843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(0.9793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(0.9959, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(0.9659, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.0136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.1829, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(1.0129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(0.9827, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(0.9963, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(0.9669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(1.2011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(0.9549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(0.8399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(0.7976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(0.9459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(0.7952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(0.8711, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(1.0398, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(0.9388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.1267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(0.8402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(0.9516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.1387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(0.8131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.0636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.1172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(1.0372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(0.8982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.3885, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(1.0213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(0.8660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(1.0273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.1818, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(1.1988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(1.0264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(0.9483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(0.7376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(0.9493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(0.9423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(0.8540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(0.9774, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(0.8852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(0.9407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(0.9438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.0719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(0.8987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.0899, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(0.9255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(0.9289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.0629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.0921, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.1317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(0.9279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(0.9674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(0.9380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(0.7834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(1.1655, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(0.7890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(0.8946, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(0.8465, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.1136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.0978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.0436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.1689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(0.9824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.0776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(0.8474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(0.9993, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(0.8536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.2277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(1.1572, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(0.9310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.0397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.0407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(0.8824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.1517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(0.8539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.1743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(0.8383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(0.9649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(0.9167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(0.8824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.1196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(0.7956, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(0.8102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(1.1521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(0.8381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(0.9217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(0.9661, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(0.9779, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(0.9161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(1.0901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(0.9148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.0117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(0.7804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(0.8287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.0473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.3255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.1282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(0.9479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(1.0833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.0570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(0.9031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(0.6934, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(0.9573, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(0.8085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(0.9698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.2416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.1046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(0.8779, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(0.7839, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(0.7514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.3469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(1.0897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(0.8210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(0.9837, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(0.9623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.1714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.1320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(0.9395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(0.7641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(0.8870, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(0.8415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.2341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(0.8217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(0.9968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(0.7946, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(0.8614, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(0.8410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(0.8290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(0.9053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(0.8875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(0.9706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(0.8709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(0.9998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(0.8960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(0.9710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(0.8390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(0.8075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(0.6812, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.0272, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(0.8185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(0.7525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.2527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(0.9863, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(0.8342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.0196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.0406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(0.9533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(0.8325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.2955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.1087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.0385, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(0.9702, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.0591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(0.8708, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(0.7750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.0630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(1.1262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(0.9516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(0.8969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(0.9238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.2893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(0.6555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.0038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(0.9013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(0.9539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.0467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(0.9239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(0.8345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.0410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(0.9643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 27\n",
            "================\n",
            "Batch No 0,\tloss is tensor(0.8087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.1255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.1294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(0.9072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(1.0278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(0.9638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(0.7499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(1.1345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(0.8263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(0.6624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(0.8481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(1.2199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(0.8934, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(1.0980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(0.9310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(0.7287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(0.9210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(1.0958, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.0988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(0.8359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(0.9042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(1.3103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(1.3609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.1508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.1684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(0.8169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(0.7626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(0.8451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(0.7394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(1.0375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.0623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.1962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(0.8010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(0.8976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(0.8271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(0.9679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(1.0563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(0.8418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(1.2401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(0.9602, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(0.9566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(0.9908, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.1347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(0.9118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(0.9079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(0.8643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(0.9249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.1498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(0.9586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(0.9318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(1.0091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(1.1155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(0.8719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(0.7938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(0.9514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(0.6862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(0.9597, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(1.0515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(0.9090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(1.1570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(0.9627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(0.7504, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.0109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(0.8135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(1.1829, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(0.8933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.1219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(0.9355, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(0.8618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.2369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(0.9369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(0.9111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.0547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(0.8788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.2069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(0.9030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(0.8687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.3861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(0.7514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(0.9636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(0.9384, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(0.8199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(0.9733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(0.7972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(0.8016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(0.9375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(1.0773, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(0.9609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(1.1062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(0.8904, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.0303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.0675, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.0107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(0.6916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(0.8968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.1408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(0.8828, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(0.9759, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(0.8233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(0.9410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.3107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(0.7315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(0.7042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(0.9655, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(0.7914, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.1000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.0488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(0.8679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(0.9247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(0.9999, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(1.0350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(0.8953, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(0.8181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(1.0309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.4669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(0.8559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(0.8981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(0.9514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.0758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(0.9182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(0.7335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.0200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(0.7481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(0.8561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(1.0694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(1.2332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(0.8050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.0886, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.0118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(0.7787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(0.8236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(0.8926, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(1.0193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(0.7943, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.2621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(1.3658, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.2301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(0.7665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(1.2123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(0.9128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(0.8122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(0.8517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(0.9183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.0051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(0.8713, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(0.8183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(0.7250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.1044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(0.7540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(0.8962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.0616, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.3065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(0.7440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(0.9951, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(0.9193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(0.9809, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(0.8318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(0.7641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.0417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(0.8381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(0.7285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.4101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.1342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.1757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(0.8289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(0.7927, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(1.2476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(0.8484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.0911, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.1129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(0.9134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(0.8900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.1937, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(0.7780, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.3837, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(1.3068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(0.9120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(0.8436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.0768, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(0.9494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.0324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(0.7420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(1.3273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(0.8928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(0.9249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(0.8965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(0.8794, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(0.8980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(0.9703, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(0.7362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(1.0953, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(0.8130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(0.8366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.0492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(0.7082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(0.8416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(0.9675, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.1354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 28\n",
            "================\n",
            "Batch No 0,\tloss is tensor(0.9930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(1.1358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(1.1316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(0.9058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(0.9724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(0.9794, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.0566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(0.7816, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.0417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(1.1680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(0.9160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(0.9929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(0.8191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(0.8032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(0.8700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(0.7740, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(0.9805, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(0.8763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(1.1232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(0.9839, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(0.9995, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(0.8427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(0.6548, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(0.9565, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(1.1032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.0158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(1.0142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(0.8869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(0.9529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(0.9822, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(0.8961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(1.0997, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(1.1506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(0.7679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(0.9945, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(1.0869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(0.9740, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(0.9277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(0.8534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(0.9936, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(1.0446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(1.0437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(1.0701, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(0.7325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(0.5810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(0.6885, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(0.8914, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(0.7620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.0454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(1.0201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(0.8988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(0.8355, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(0.8592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(0.8330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(1.0079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(1.0166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(0.7372, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(0.9736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(0.8613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(0.8695, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(0.9518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(0.7365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(0.9657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(0.8176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(0.9032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(0.8610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.3613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(0.9451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(1.2686, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(0.9668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(0.9515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(0.7965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(0.9763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(1.3832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(1.1097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(0.8709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(1.0492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.0494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(1.0107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(0.7532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(0.8654, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(0.6492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(0.6544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(1.1166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(0.7410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(0.7852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(0.9018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(1.0390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(0.8585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(1.0440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(1.0144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(0.8790, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(0.7166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(1.0123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.0610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(0.9325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.0413, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(0.9286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(0.8952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.1638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(1.0199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(0.8406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.1336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.0258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(0.9633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(1.1359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.2309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.2394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(0.9534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(0.8996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(1.1960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(0.6039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(0.7511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(0.9702, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(0.8465, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(0.7333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(1.1929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(0.8917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(0.9553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(1.3717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.0996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(0.9685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(0.8595, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(1.3534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(1.0184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(0.9282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(0.8944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(0.7666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(0.8610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(0.8377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(0.9492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(0.9017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(1.2266, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(0.8941, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(0.8587, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.2757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(0.7023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(1.2427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(0.7532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(0.9057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(0.8822, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(0.8492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(0.9698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(0.9281, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.1901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(1.1138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.1129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(0.9369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.0592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.0086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(0.9852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(0.8463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.1619, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(0.9708, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(0.9198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(0.6152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(1.0108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(0.6450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(1.2080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.1611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.0174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(0.9821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(0.8346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(1.1056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(1.1857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.0162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(0.8856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(0.8994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(0.9661, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(0.9758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(0.8998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.4139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(0.8350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(1.1945, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(1.1401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.0479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(0.7392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(0.7722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(0.6438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(1.0515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(0.9948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.0990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(0.8687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(0.9875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(1.2818, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(0.9563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(1.1294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(1.2357, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.3635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(1.0396, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(0.8436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(0.9641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(1.1156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.0245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(0.9927, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(0.8752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(0.8593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(0.9647, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(1.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Epoch No 29\n",
            "================\n",
            "Batch No 0,\tloss is tensor(0.9878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 1,\tloss is tensor(0.9722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 2,\tloss is tensor(0.8667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 3,\tloss is tensor(1.3190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 4,\tloss is tensor(0.8935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 5,\tloss is tensor(0.9764, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 6,\tloss is tensor(1.1694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 7,\tloss is tensor(0.7751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 8,\tloss is tensor(1.1628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 9,\tloss is tensor(0.6333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 10,\tloss is tensor(0.9118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 11,\tloss is tensor(0.7649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 12,\tloss is tensor(0.7918, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 13,\tloss is tensor(0.8897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 14,\tloss is tensor(0.6967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 15,\tloss is tensor(0.8623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 16,\tloss is tensor(0.7613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 17,\tloss is tensor(0.8397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 18,\tloss is tensor(0.8700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 19,\tloss is tensor(0.8230, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 20,\tloss is tensor(0.8132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 21,\tloss is tensor(0.9358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 22,\tloss is tensor(0.6217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 23,\tloss is tensor(1.0478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 24,\tloss is tensor(0.8362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 25,\tloss is tensor(1.1788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 26,\tloss is tensor(0.8681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 27,\tloss is tensor(0.9010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 28,\tloss is tensor(0.8783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 29,\tloss is tensor(0.8923, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 30,\tloss is tensor(1.0450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 31,\tloss is tensor(0.7854, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 32,\tloss is tensor(0.9019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 33,\tloss is tensor(0.8338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 34,\tloss is tensor(0.8954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 35,\tloss is tensor(0.7657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 36,\tloss is tensor(0.8889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 37,\tloss is tensor(0.8471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 38,\tloss is tensor(0.7326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 39,\tloss is tensor(0.7672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 40,\tloss is tensor(0.7467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 41,\tloss is tensor(0.7885, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 42,\tloss is tensor(0.9718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 43,\tloss is tensor(0.8439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 44,\tloss is tensor(0.9962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 45,\tloss is tensor(0.8948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 46,\tloss is tensor(1.1834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 47,\tloss is tensor(1.0349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 48,\tloss is tensor(1.4016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 49,\tloss is tensor(0.8503, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 50,\tloss is tensor(0.7938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 51,\tloss is tensor(0.9324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 52,\tloss is tensor(1.0733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 53,\tloss is tensor(0.9347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 54,\tloss is tensor(0.9733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 55,\tloss is tensor(0.8697, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 56,\tloss is tensor(0.8051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 57,\tloss is tensor(0.8874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 58,\tloss is tensor(0.9646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 59,\tloss is tensor(0.8179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 60,\tloss is tensor(0.9566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 61,\tloss is tensor(0.7594, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 62,\tloss is tensor(1.0758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 63,\tloss is tensor(0.9117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 64,\tloss is tensor(0.9381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 65,\tloss is tensor(0.9267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 66,\tloss is tensor(1.0333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 67,\tloss is tensor(0.6805, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 68,\tloss is tensor(0.8995, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 69,\tloss is tensor(1.2009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 70,\tloss is tensor(0.7925, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 71,\tloss is tensor(1.0222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 72,\tloss is tensor(1.4771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 73,\tloss is tensor(0.8995, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 74,\tloss is tensor(0.8195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 75,\tloss is tensor(1.1081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 76,\tloss is tensor(0.9021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 77,\tloss is tensor(1.0782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 78,\tloss is tensor(0.9639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 79,\tloss is tensor(1.2197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 80,\tloss is tensor(1.1195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 81,\tloss is tensor(0.9416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 82,\tloss is tensor(1.1018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 83,\tloss is tensor(0.9958, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 84,\tloss is tensor(0.6861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 85,\tloss is tensor(1.0319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 86,\tloss is tensor(1.1053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 87,\tloss is tensor(0.8391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 88,\tloss is tensor(0.9034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 89,\tloss is tensor(0.9685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 90,\tloss is tensor(0.8246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 91,\tloss is tensor(0.7222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 92,\tloss is tensor(1.2296, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 93,\tloss is tensor(1.1116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 94,\tloss is tensor(0.8680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 95,\tloss is tensor(1.0808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 96,\tloss is tensor(1.0117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 97,\tloss is tensor(1.3216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 98,\tloss is tensor(0.7868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 99,\tloss is tensor(0.8055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 100,\tloss is tensor(1.0640, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 101,\tloss is tensor(0.8809, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 102,\tloss is tensor(0.5843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 103,\tloss is tensor(1.0149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 104,\tloss is tensor(1.1160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 105,\tloss is tensor(1.0386, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 106,\tloss is tensor(0.8782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 107,\tloss is tensor(1.0378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 108,\tloss is tensor(1.0223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 109,\tloss is tensor(1.2277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 110,\tloss is tensor(1.0738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 111,\tloss is tensor(0.7987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 112,\tloss is tensor(0.8016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 113,\tloss is tensor(0.9962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 114,\tloss is tensor(0.9182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 115,\tloss is tensor(0.8375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 116,\tloss is tensor(1.0617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 117,\tloss is tensor(0.8310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 118,\tloss is tensor(0.9213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 119,\tloss is tensor(0.8497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 120,\tloss is tensor(0.8905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 121,\tloss is tensor(1.1046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 122,\tloss is tensor(0.8753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 123,\tloss is tensor(1.1083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 124,\tloss is tensor(0.9959, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 125,\tloss is tensor(0.9788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 126,\tloss is tensor(0.9229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 127,\tloss is tensor(0.9654, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 128,\tloss is tensor(0.8473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 129,\tloss is tensor(1.0467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 130,\tloss is tensor(1.5711, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 131,\tloss is tensor(0.9227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 132,\tloss is tensor(1.0240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 133,\tloss is tensor(0.8561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 134,\tloss is tensor(0.9084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 135,\tloss is tensor(1.2121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 136,\tloss is tensor(1.0058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 137,\tloss is tensor(0.8031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 138,\tloss is tensor(0.8023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 139,\tloss is tensor(0.6719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 140,\tloss is tensor(0.7842, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 141,\tloss is tensor(0.9598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 142,\tloss is tensor(0.8856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 143,\tloss is tensor(0.6913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 144,\tloss is tensor(1.1743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 145,\tloss is tensor(1.0857, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 146,\tloss is tensor(0.9355, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 147,\tloss is tensor(1.1325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 148,\tloss is tensor(0.9967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 149,\tloss is tensor(1.0992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 150,\tloss is tensor(1.2686, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 151,\tloss is tensor(1.1821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 152,\tloss is tensor(1.0323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 153,\tloss is tensor(1.0000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 154,\tloss is tensor(0.9521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 155,\tloss is tensor(1.1319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 156,\tloss is tensor(1.1714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 157,\tloss is tensor(0.8124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 158,\tloss is tensor(0.8047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 159,\tloss is tensor(0.8524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 160,\tloss is tensor(1.0928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 161,\tloss is tensor(1.2687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 162,\tloss is tensor(0.8567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 163,\tloss is tensor(1.3485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 164,\tloss is tensor(0.9343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 165,\tloss is tensor(0.8275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 166,\tloss is tensor(1.1547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 167,\tloss is tensor(1.0831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 168,\tloss is tensor(0.9994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 169,\tloss is tensor(1.1337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 170,\tloss is tensor(1.0465, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 171,\tloss is tensor(1.1703, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 172,\tloss is tensor(1.1819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 173,\tloss is tensor(1.1433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 174,\tloss is tensor(0.9792, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 175,\tloss is tensor(0.9204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 176,\tloss is tensor(1.1029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 177,\tloss is tensor(0.8352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 178,\tloss is tensor(1.0445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 179,\tloss is tensor(1.1139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 180,\tloss is tensor(0.8978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 181,\tloss is tensor(0.5883, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 182,\tloss is tensor(1.1027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 183,\tloss is tensor(0.8096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 184,\tloss is tensor(0.7760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 185,\tloss is tensor(0.9480, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 186,\tloss is tensor(0.8268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 187,\tloss is tensor(0.9402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 188,\tloss is tensor(0.8842, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 189,\tloss is tensor(1.2627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 190,\tloss is tensor(0.7412, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 191,\tloss is tensor(0.7784, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 192,\tloss is tensor(0.8319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 193,\tloss is tensor(0.8950, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 194,\tloss is tensor(1.0231, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 195,\tloss is tensor(1.1834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 196,\tloss is tensor(1.0758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 197,\tloss is tensor(0.8139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 198,\tloss is tensor(1.0974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Batch No 199,\tloss is tensor(0.9093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NN(\n",
              "  (fc1): Linear(in_features=26, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
              "  (fc3): Linear(in_features=32, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_model(dataloader=testLoaderMFCC, cost_func=nn.CrossEntropyLoss(), model=model, device='cuda')"
      ],
      "metadata": {
        "id": "fjWV-gI7Wxis",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f4da2f7-2138-4283-f898-05a27f9d6665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:\t\t\t\t tensor(1.0312)\n",
            "F1 Macro-Averaged Score:\t 0.5278096386528143\n",
            "Accuracy:\t\t\t 0.5450581395348837\n",
            "Confusion Matrix:\t [[102  84  37 101]\n",
            " [ 20 268   2   7]\n",
            " [137  43 128  48]\n",
            " [ 39  84  24 252]] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Παρατηρούμε ότι η εκπαίδευση του μοντέλου στη CPU έγινε σε περίπου 21 δευτερόλεπτα, ενώ στη GPU σε 28"
      ],
      "metadata": {
        "id": "dQnxQZ_GjLvX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Βήμα 7: Επιλογή Μοντέλου"
      ],
      "metadata": {
        "id": "byrWJgabWzSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_select(epochs, optimizer, trainloader, valloader, cost_func, model, device='cpu'):\n",
        "  device = torch.device(device)\n",
        "  max_f1 = 0\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    for batch, (data, targets) in enumerate(trainloader):\n",
        "      data = data.to(device=device)\n",
        "      targets = targets.to(device=device)\n",
        "\n",
        "      scores = model(data)\n",
        "      loss = cost_func(scores, targets)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      scores_all = []\n",
        "      targets_all = []\n",
        "\n",
        "      for data, targets in valloader:\n",
        "        data = data.to(device=device)\n",
        "        targets = targets.to(device=device)\n",
        "\n",
        "        scores = model(data)\n",
        "\n",
        "        scores_all.append(scores)\n",
        "        targets_all.append(targets)\n",
        "\n",
        "      scores_all = torch.cat(scores_all, 0)\n",
        "      targets_all = torch.cat(targets_all, 0)\n",
        "\n",
        "      _, pred = scores_all.max(1)\n",
        "\n",
        "      f1 = f1_score(targets_all, pred, average='macro')\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    if f1 > max_f1:\n",
        "      max_f1 = f1\n",
        "      best_model = model\n",
        "\n",
        "  return best_model"
      ],
      "metadata": {
        "id": "aGQd1DYhW3HT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NN(input_size=26, num_classes=4).to(torch.device('cpu'))\n",
        "\n",
        "model = train_model_select(epochs=30, optimizer=SGD(model.parameters(), lr=0.002), trainloader=trainLoaderMFCC, valloader=valLoaderMFCC, cost_func=nn.CrossEntropyLoss(), model=model, device='cpu')\n",
        "eval_model(dataloader=testLoaderMFCC, cost_func=nn.CrossEntropyLoss(), model=model, device='cpu')"
      ],
      "metadata": {
        "id": "vH8XoJUKV7nj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f71ebfe0-ff6d-4f4b-d490-1351cca80256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:\t\t\t\t tensor(1.0582)\n",
            "F1 Macro-Averaged Score:\t 0.580742241418351\n",
            "Accuracy:\t\t\t 0.5879360465116279\n",
            "Confusion Matrix:\t [[ 86  26  58 154]\n",
            " [ 47 228   6  16]\n",
            " [ 74  13 212  57]\n",
            " [ 51  26  39 283]] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ερώτημα 2: Convolutional Neural Networks"
      ],
      "metadata": {
        "id": "lyroKUvuXgTM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Βήμα 1: Φόρτωση Δεδομένων (Spectograms)"
      ],
      "metadata": {
        "id": "E8oZ4uXmXoha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mel_trainX = np.load(data_url + '/train/melgrams/X.npy')\n",
        "mel_trainY = np.load(data_url + '/train/melgrams/labels.npy')\n",
        "\n",
        "mel_testX = np.load(data_url + '/test/melgrams/X.npy')\n",
        "mel_testY = np.load(data_url + '/test/melgrams/labels.npy')\n",
        "\n",
        "mel_valX = np.load(data_url + '/val/melgrams/X.npy')\n",
        "mel_valY = np.load(data_url + '/val/melgrams/labels.npy')"
      ],
      "metadata": {
        "id": "kUzdeDpaXv12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mel_trainY = np.array([mapping[label] for label in mel_trainY])\n",
        "\n",
        "mel_testY = np.array([mapping[label] for label in mel_testY])\n",
        "\n",
        "mel_valY = np.array([mapping[label] for label in mel_valY])"
      ],
      "metadata": {
        "id": "-Kms6b3scpYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "img = librosa.display.specshow(mel_trainX[np.where(mel_trainY == 0)[0][0]], x_axis='time', y_axis='mel', ax=ax)\n",
        "ax.set(title='blues')\n",
        "plt.colorbar(img, format='%+2.0f dB')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "RngJgGVwVV7k",
        "outputId": "6983768a-b831-46ca-d999-3d520f60715e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f25140c6690>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "img = librosa.display.specshow(mel_trainX[np.where(mel_trainY == 1)[0][0]], x_axis='time', y_axis='mel', ax=ax)\n",
        "ax.set(title='classical')\n",
        "plt.colorbar(img, format='%+2.0f dB')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "HGr6YsyVVVyV",
        "outputId": "4bc95bdd-d56d-423d-dd55-a83499977d82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f2510d4f450>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "img = librosa.display.specshow(mel_trainX[np.where(mel_trainY == 2)[0][0]], x_axis='time', y_axis='mel', ax=ax)\n",
        "ax.set(title='hiphop')\n",
        "plt.colorbar(img, format='%+2.0f dB')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "qeaFhpb9VVlL",
        "outputId": "89ed6cd7-9faa-49bd-ffec-f8fbe2bfd329"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f2510c8d510>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "img = librosa.display.specshow(mel_trainX[np.where(mel_trainY == 3)[0][0]], x_axis='time', y_axis='mel', ax=ax)\n",
        "ax.set(title='rock_metal_hardrock')\n",
        "plt.colorbar(img, format='%+2.0f dB')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "uZ50FGt0TfEL",
        "outputId": "f9f98ff2-176c-4e67-e51e-fe0423200c75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f2510bd2410>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class trainDataSetMEL(Dataset):\n",
        "  def __init__(self):\n",
        "    self.x = torch.Tensor(mel_trainX.tolist())\n",
        "    self.y = torch.LongTensor(mel_trainY.tolist())\n",
        "\n",
        "    self.n_samples = len(self.x)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.x[index], self.y[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_samples\n",
        "\n",
        "\n",
        "class testDataSetMEL(Dataset):\n",
        "  def __init__(self):\n",
        "    self.x = torch.Tensor(mel_testX.tolist())\n",
        "    self.y = torch.LongTensor(mel_testY.tolist())\n",
        "\n",
        "    self.n_samples = len(self.x)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.x[index], self.y[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_samples\n",
        "\n",
        "\n",
        "class valDataSetMEL(Dataset):\n",
        "  def __init__(self):\n",
        "    self.x = torch.Tensor(mel_valX.tolist())\n",
        "    self.y = torch.LongTensor(mel_valY.tolist())\n",
        "\n",
        "    self.n_samples = len(self.x)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.x[index], self.y[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_samples"
      ],
      "metadata": {
        "id": "5tzleMUDefjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainLoaderMEL = DataLoader(dataset=trainDataSetMEL(), batch_size=16, shuffle=True)\n",
        "\n",
        "testLoaderMEL = DataLoader(dataset=testDataSetMEL(), batch_size=16, shuffle=False)\n",
        "\n",
        "valLoaderMEL = DataLoader(dataset=valDataSetMEL(), batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "id": "f6KQBtCLep3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Βήμα 2: Ορισμός Νευρωνικού Δικτύου"
      ],
      "metadata": {
        "id": "O7lXSUs0e_x_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_no_pool(nn.Module):\n",
        "  def __init__(self, num_classes=10):\n",
        "    super(CNN_no_pool, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5)\n",
        "    self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5)\n",
        "    self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5)\n",
        "    self.fc1 = nn.Linear(128, 1024)\n",
        "    self.fc2 = nn.Linear(1024, 256)\n",
        "    self.fc3 = nn.Linear(256, 32)\n",
        "    self.fc4 = nn.Linear(32, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = F.relu(self.conv3(x))\n",
        "    x = F.relu(self.conv4(x))\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "g4VTle2XfHUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Βήμα 3: Εκπαίδευση Δικτύου"
      ],
      "metadata": {
        "id": "KEEGYAcqfMNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_cnn(epochs, optimizer, dataloader, cost_func, model, device='cpu'):\n",
        "  device = torch.device(device)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    print('Epoch No ', epoch, '\\n================', sep='')\n",
        "\n",
        "    for batch, (data, targets) in enumerate(dataloader):\n",
        "      data = data.to(device=device)\n",
        "      targets = targets.to(device=device)\n",
        "\n",
        "      scores = model(data)\n",
        "      loss = cost_func(scores, targets)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      print('Batch No ', batch, ',\\tloss is ', loss, sep='')\n",
        "\n",
        "    print('')\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "cwFfPXp7SKet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model_cnn(dataloader, cost_func, model, device='cpu'):\n",
        "  device = torch.device(device)\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "\n",
        "    scores_all = []\n",
        "    targets_all = []\n",
        "\n",
        "    for data, targets in dataloader:\n",
        "      data = data.to(device=device)\n",
        "      targets = targets.to(device=device)\n",
        "\n",
        "      scores = model(data)\n",
        "\n",
        "      scores_all.append(scores)\n",
        "      targets_all.append(targets)\n",
        "\n",
        "    scores_all = torch.cat(scores_all, 0).cpu()\n",
        "    targets_all = torch.cat(targets_all, 0).cpu()\n",
        "\n",
        "    _, pred = scores_all.max(1)\n",
        "\n",
        "    loss = cost_func(scores_all, targets_all)\n",
        "    f1 = f1_score(targets_all, pred, average='macro')\n",
        "    acc = accuracy_score(targets_all, pred)\n",
        "    mat = confusion_matrix(targets_all, pred)\n",
        "\n",
        "    print('Loss:\\t\\t\\t\\t', loss)\n",
        "    print('F1 Macro-Averaged Score:\\t', f1)\n",
        "    print('Accuracy:\\t\\t\\t', acc)\n",
        "    print('Confusion Matrix:\\t', mat, '\\n')\n",
        "\n",
        "  model.train()"
      ],
      "metadata": {
        "id": "Uh7kgHyXVf0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN_no_pool(num_classes=10).to(torch.device('cpu'))\n",
        "\n",
        "train_model_cnn(epochs=30, optimizer=SGD(model.parameters(), lr=0.002), dataloader=trainLoaderMFCC, cost_func=nn.CrossEntropyLoss(), model=model)"
      ],
      "metadata": {
        "id": "S63qaXTvfQvW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "75375f1c-128b-4e3c-d27e-581ad93db780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch No 0\n",
            "================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-e963c77a40a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN_no_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_model_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.002\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainLoaderMFCC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-b8a94ffc407e>\u001b[0m in \u001b[0;36mtrain_model_cnn\u001b[0;34m(epochs, optimizer, dataloader, cost_func, model, device)\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m       \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcost_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-c86da3791463>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    453\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 454\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [16, 26]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Βήμα 4: Pooling and Padding"
      ],
      "metadata": {
        "id": "OgXCBD-pfQMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self, num_classes=10):\n",
        "    super(CNN, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, padding=2)\n",
        "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, padding=2)\n",
        "    self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=2)\n",
        "    self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, padding=2)\n",
        "\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    self.fc1 = nn.Linear(128, 1024)\n",
        "    self.fc2 = nn.Linear(1024, 256)\n",
        "    self.fc3 = nn.Linear(256, 32)\n",
        "    self.fc4 = nn.Linear(32, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = self.pool(x)\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = self.pool(x)\n",
        "    x = F.relu(self.conv3(x))\n",
        "    x = self.pool(x)\n",
        "    x = F.relu(self.conv4(x))\n",
        "    x = self.pool(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "iCC7RzbdhVIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN(num_classes=10).to(torch.device('cpu'))\n",
        "\n",
        "train_model_cnn(epochs=30, optimizer=SGD(model.parameters(), lr=0.002), dataloader=trainLoaderMFCC, cost_func=nn.CrossEntropyLoss(), model=model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "sDdRrH8hW70r",
        "outputId": "00fa5970-2f85-4441-bb9a-b28a29b3dd62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch No 0\n",
            "================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-9ffe31a2b2fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_model_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.002\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainLoaderMFCC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-b8a94ffc407e>\u001b[0m in \u001b[0;36mtrain_model_cnn\u001b[0;34m(epochs, optimizer, dataloader, cost_func, model, device)\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m       \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcost_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-25d748bb067f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    453\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 454\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [16, 26]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Πηγές"
      ],
      "metadata": {
        "id": "IrRDkN4GY67M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* https://aladdinpersson.medium.com/pytorch-neural-network-tutorial-7e871d6be7c4\n",
        "* https://www.youtube.com/watch?v=wnK3uWv_WkU\n",
        "* https://pyimagesearch.com/2021/07/12/intro-to-pytorch-training-your-first-neural-network-using-pytorch/\n",
        "* https://openclassrooms.com/en/courses/6532316-introduction-to-deep-learning-models/6999381-train-a-deeper-fully-connected-neural-network\n",
        "* https://towardsdatascience.com/math-neural-network-from-scratch-in-python-d6da9f29ce65"
      ],
      "metadata": {
        "id": "ABZgnjPqZDqE"
      }
    }
  ]
}